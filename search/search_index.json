{"config":{"lang":["pt"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"],"fields":{"title":{"boost":1000.0},"text":{"boost":1.0},"tags":{"boost":1000000.0}}},"docs":[{"location":"","title":"\ud83d\udcda Documenta\u00e7\u00e3o: LLMs as a Judge","text":"<p>Bem-vindo \u00e0 documenta\u00e7\u00e3o completa sobre LLMs as a Judge - estudo profundo sobre o uso de modelos de linguagem grandes para avaliar agentes de IA.</p>"},{"location":"#comece-aqui","title":"\ud83d\ude80 Comece Aqui","text":"<p>Novo no tema? Comece pelo Quick Start Guide - voc\u00ea estar\u00e1 avaliando agentes em 5 minutos!</p> <p>Quer uma vis\u00e3o geral r\u00e1pida? Leia o Resumo Executivo</p> <p>Pronto para mergulhar fundo? Acesse o Estudo Completo</p>"},{"location":"#documentos-disponiveis","title":"\ud83d\udcd6 Documentos Dispon\u00edveis","text":""},{"location":"#guias-praticos","title":"\ud83c\udfaf Guias Pr\u00e1ticos","text":"<ul> <li>Quick Start Guide \u26a1</li> <li>Comece em 5 minutos</li> <li>Exemplos pr\u00e1ticos imediatos</li> <li> <p>Configura\u00e7\u00e3o b\u00e1sica</p> </li> <li> <p>Resumo Executivo \ud83d\udcca</p> </li> <li>Principais conclus\u00f5es</li> <li>Modelos recomendados</li> <li>Recomenda\u00e7\u00f5es pr\u00e1ticas</li> <li>M\u00e9tricas importantes</li> </ul>"},{"location":"#estudo-completo","title":"\ud83d\udcda Estudo Completo","text":"<ul> <li>LLMs as a Judge - Estudo Completo \ud83d\udcd6</li> <li>Estudo profundo e abrangente</li> <li>An\u00e1lise comparativa de modelos</li> <li>Integra\u00e7\u00e3o com ADK e Langfuse</li> <li>Exemplos pr\u00e1ticos completos</li> <li>M\u00e9tricas e benchmarks</li> <li>Melhores pr\u00e1ticas</li> </ul>"},{"location":"#navegacao","title":"\ud83d\uddfa\ufe0f Navega\u00e7\u00e3o","text":"<ul> <li>\u00cdndice Completo \ud83d\uddc2\ufe0f</li> <li>Organiza\u00e7\u00e3o de todos os documentos</li> <li>Roteiros de leitura</li> <li> <p>Busca r\u00e1pida por t\u00f3pico</p> </li> <li> <p>Guia de Deploy \ud83d\ude80</p> </li> <li>Como publicar no GitHub</li> <li>Visualizar como GitBook</li> <li>GitHub Pages + MkDocs</li> </ul>"},{"location":"#codigo-e-exemplos","title":"\ud83d\udcbb C\u00f3digo e Exemplos","text":"<p>Todo o c\u00f3digo pr\u00e1tico est\u00e1 em <code>../examples/</code>:</p> <ul> <li>Implementa\u00e7\u00e3o Completa - Classes Python prontas</li> <li>Templates de Prompts - Templates reutiliz\u00e1veis</li> <li>Configura\u00e7\u00f5es - Configura\u00e7\u00f5es recomendadas</li> <li>README dos Exemplos - Documenta\u00e7\u00e3o dos exemplos</li> </ul>"},{"location":"#roteiros-de-leitura","title":"\ud83c\udfaf Roteiros de Leitura","text":""},{"location":"#para-iniciantes","title":"Para Iniciantes","text":"<ol> <li>Quick Start Guide</li> <li>Resumo Executivo</li> <li>Implementa\u00e7\u00e3o Completa</li> <li>Estudo Completo</li> </ol>"},{"location":"#para-desenvolvedores","title":"Para Desenvolvedores","text":"<ol> <li>Quick Start Guide</li> <li>Implementa\u00e7\u00e3o Completa</li> <li>Templates de Prompts</li> <li>Estudo Completo - Se\u00e7\u00f5es t\u00e9cnicas</li> </ol>"},{"location":"#para-gestoresarquitetos","title":"Para Gestores/Arquitetos","text":"<ol> <li>Resumo Executivo</li> <li>Estudo Completo - Se\u00e7\u00f5es 1, 2, 9</li> <li>Configura\u00e7\u00f5es Recomendadas</li> </ol>"},{"location":"#busca-rapida","title":"\ud83d\udd0d Busca R\u00e1pida","text":"<ul> <li>\"Como come\u00e7ar?\" \u2192 Quick Start Guide</li> <li>\"Qual modelo usar?\" \u2192 Resumo Executivo</li> <li>\"Como integrar com ADK?\" \u2192 Estudo Completo - Se\u00e7\u00e3o 3</li> <li>\"Como integrar com Langfuse?\" \u2192 Estudo Completo - Se\u00e7\u00e3o 4</li> <li>\"Quais s\u00e3o as melhores pr\u00e1ticas?\" \u2192 Estudo Completo - Se\u00e7\u00e3o 7</li> </ul>"},{"location":"#topicos-principais","title":"\ud83d\udccb T\u00f3picos Principais","text":""},{"location":"#conceitos","title":"Conceitos","text":"<ul> <li>\u2705 O que s\u00e3o LLMs as a Judge</li> <li>\u2705 Por que usar LLMs como Judge</li> <li>\u2705 Tipos de avalia\u00e7\u00e3o</li> </ul>"},{"location":"#modelos","title":"Modelos","text":"<ul> <li>\u2705 An\u00e1lise comparativa (GPT-4, Gemini, Claude, etc.)</li> <li>\u2705 Crit\u00e9rios de sele\u00e7\u00e3o</li> <li>\u2705 Recomenda\u00e7\u00f5es por caso de uso</li> </ul>"},{"location":"#integracao","title":"Integra\u00e7\u00e3o","text":"<ul> <li>\u2705 Google ADK</li> <li>\u2705 Langfuse</li> <li>\u2705 Exemplos pr\u00e1ticos</li> </ul>"},{"location":"#praticas","title":"Pr\u00e1ticas","text":"<ul> <li>\u2705 Design de prompts</li> <li>\u2705 Otimiza\u00e7\u00e3o de custo</li> <li>\u2705 M\u00e9tricas e benchmarks</li> <li>\u2705 Tratamento de erros</li> </ul>"},{"location":"#estrutura-do-estudo","title":"\ud83c\udf93 Estrutura do Estudo","text":"<pre><code>docs/\n\u251c\u2500\u2500 README.md                          # Este arquivo\n\u251c\u2500\u2500 INDEX_LLMs_Judge.md                # \u00cdndice completo\n\u251c\u2500\u2500 QUICK_START_JUDGE.md               # Guia r\u00e1pido\n\u251c\u2500\u2500 RESUMO_EXECUTIVO_LLMs_Judge.md     # Resumo executivo\n\u2514\u2500\u2500 LLMs_as_Judge_Study.md             # Estudo completo\n</code></pre>"},{"location":"#status-do-projeto","title":"\ud83d\udcca Status do Projeto","text":"<ul> <li>\u2705 Estudo completo finalizado</li> <li>\u2705 Exemplos de c\u00f3digo implementados</li> <li>\u2705 Templates de prompts criados</li> <li>\u2705 Configura\u00e7\u00f5es recomendadas documentadas</li> <li>\u2705 Documenta\u00e7\u00e3o completa</li> </ul>"},{"location":"#proximos-passos","title":"\ud83d\ude80 Pr\u00f3ximos Passos","text":"<ol> <li>\u2705 Leia o Quick Start Guide</li> <li>\u2705 Execute os exemplos pr\u00e1ticos</li> <li>\u2705 Leia o Resumo Executivo</li> <li>\u2705 Estude a Implementa\u00e7\u00e3o Completa</li> <li>\u2705 Leia o Estudo Completo</li> <li>\u2705 Adapte para seus casos de uso espec\u00edficos</li> </ol>"},{"location":"#suporte","title":"\ud83d\udcde Suporte","text":"<ul> <li>D\u00favidas sobre conceitos: Estudo Completo</li> <li>D\u00favidas sobre c\u00f3digo: Implementa\u00e7\u00e3o Completa</li> <li>D\u00favidas sobre uso: Quick Start Guide</li> <li>Navega\u00e7\u00e3o: \u00cdndice Completo</li> </ul> <p>Vers\u00e3o: 1.0 Data: 2024 Status: \u2705 Completo e Pronto para Uso</p> <p>Boa leitura e implementa\u00e7\u00e3o! \ud83c\udf89</p>"},{"location":"DEPLOYMENT_GUIDE/","title":"\ud83d\ude80 Guia de Deploy: Publicando Documenta\u00e7\u00e3o no GitHub","text":"<p>Este guia mostra como publicar a documenta\u00e7\u00e3o do estudo LLMs as a Judge no GitHub e visualiz\u00e1-la como uma p\u00e1gina profissional.</p>"},{"location":"DEPLOYMENT_GUIDE/#opcoes-disponiveis","title":"\ud83d\udccb Op\u00e7\u00f5es Dispon\u00edveis","text":""},{"location":"DEPLOYMENT_GUIDE/#1-gitbook-recomendado-mais-facil","title":"1. GitBook (Recomendado - Mais F\u00e1cil)","text":"<p>\u2705 Interface visual moderna \u2705 Sincroniza\u00e7\u00e3o autom\u00e1tica com GitHub \u2705 F\u00e1cil de usar \u26a0\ufe0f Requer conta GitBook (gratuita)</p>"},{"location":"DEPLOYMENT_GUIDE/#2-github-pages-mkdocs-recomendado-open-source","title":"2. GitHub Pages + MkDocs (Recomendado - Open Source)","text":"<p>\u2705 Totalmente gratuito \u2705 Controle total \u2705 Customiz\u00e1vel \u26a0\ufe0f Requer configura\u00e7\u00e3o inicial</p>"},{"location":"DEPLOYMENT_GUIDE/#3-docusaurus-alternativa","title":"3. Docusaurus (Alternativa)","text":"<p>\u2705 Moderno e r\u00e1pido \u2705 Suporte a React \u26a0\ufe0f Requer mais configura\u00e7\u00e3o</p>"},{"location":"DEPLOYMENT_GUIDE/#opcao-1-gitbook-mais-facil","title":"\ud83c\udfaf Op\u00e7\u00e3o 1: GitBook (Mais F\u00e1cil)","text":""},{"location":"DEPLOYMENT_GUIDE/#passo-1-criar-repositorio-no-github","title":"Passo 1: Criar Reposit\u00f3rio no GitHub","text":"<pre><code># 1. Crie um novo reposit\u00f3rio no GitHub\n# Acesse: https://github.com/new\n# Nome sugerido: llm-as-a-judge-study\n\n# 2. No terminal, navegue at\u00e9 o diret\u00f3rio do projeto\ncd llm-as-a-judge-study\n\n# 3. Inicialize git (se ainda n\u00e3o tiver)\ngit init\n\n# 4. Adicione os arquivos\ngit add docs/ examples/\n\n# 5. Commit inicial\ngit commit -m \"docs: Adiciona estudo completo sobre LLMs as a Judge\"\n\n# 6. Adicione o remote do GitHub\ngit remote add origin https://github.com/flaviohbonfim/llm-as-a-judge-study.git\n\n# 7. Push para GitHub\ngit branch -M main\ngit push -u origin main\n</code></pre>"},{"location":"DEPLOYMENT_GUIDE/#passo-2-conectar-com-gitbook","title":"Passo 2: Conectar com GitBook","text":"<ol> <li>Acesse GitBook: https://www.gitbook.com/</li> <li>Crie uma conta (gratuita)</li> <li>Crie um novo espa\u00e7o (Space)</li> <li>Escolha \"Import from GitHub\"</li> <li>Conecte seu reposit\u00f3rio GitHub</li> <li>Selecione o reposit\u00f3rio <code>llm-as-a-judge-study</code></li> <li>Configure o caminho: <code>/docs</code> (ou raiz se preferir)</li> </ol>"},{"location":"DEPLOYMENT_GUIDE/#passo-3-configurar-estrutura-no-gitbook","title":"Passo 3: Configurar Estrutura no GitBook","text":"<p>Crie um arquivo <code>SUMMARY.md</code> na raiz do reposit\u00f3rio para organizar a navega\u00e7\u00e3o:</p> <pre><code># LLMs as a Judge - Estudo Completo\n\n* [Introdu\u00e7\u00e3o](README.md)\n* [\u00cdndice](INDEX_LLMs_Judge.md)\n* [Quick Start](QUICK_START_JUDGE.md)\n* [Resumo Executivo](RESUMO_EXECUTIVO_LLMs_Judge.md)\n* [Estudo Completo](LLMs_as_Judge_Study.md)\n* [Guia de Deploy](DEPLOYMENT_GUIDE.md)\n</code></pre>"},{"location":"DEPLOYMENT_GUIDE/#passo-4-sincronizacao-automatica","title":"Passo 4: Sincroniza\u00e7\u00e3o Autom\u00e1tica","text":"<p>O GitBook sincroniza automaticamente com o GitHub. Toda vez que voc\u00ea fizer push, a documenta\u00e7\u00e3o ser\u00e1 atualizada.</p>"},{"location":"DEPLOYMENT_GUIDE/#opcao-2-github-pages-mkdocs-recomendado-para-controle-total","title":"\ud83c\udfaf Op\u00e7\u00e3o 2: GitHub Pages + MkDocs (Recomendado para Controle Total)","text":""},{"location":"DEPLOYMENT_GUIDE/#passo-1-criar-repositorio-no-github_1","title":"Passo 1: Criar Reposit\u00f3rio no GitHub","text":"<pre><code># Mesmo processo da Op\u00e7\u00e3o 1\ncd llm-as-a-judge-study\ngit init\ngit add .\ngit commit -m \"docs: Adiciona estudo completo sobre LLMs as a Judge\"\ngit remote add origin https://github.com/flaviohbonfim/llm-as-a-judge-study.git\ngit branch -M main\ngit push -u origin main\n</code></pre>"},{"location":"DEPLOYMENT_GUIDE/#passo-2-configurar-mkdocs","title":"Passo 2: Configurar MkDocs","text":"<p>Crie um arquivo <code>mkdocs.yml</code> na raiz do projeto:</p> <pre><code>site_name: LLMs as a Judge - Estudo Completo\nsite_description: Estudo profundo sobre uso de LLMs para avaliar agentes de IA\nsite_author: Seu Nome\nsite_url: https://flaviohbonfim.github.io/llm-as-a-judge-study\n\ntheme:\n  name: material\n  palette:\n    - scheme: default\n      primary: blue\n      accent: blue\n      toggle:\n        icon: material/brightness-7\n        name: Switch to dark mode\n    - scheme: slate\n      primary: blue\n      accent: blue\n      toggle:\n        icon: material/brightness-4\n        name: Switch to light mode\n  features:\n    - navigation.tabs\n    - navigation.sections\n    - navigation.expand\n    - navigation.top\n    - search.suggest\n    - search.highlight\n    - content.code.annotate\n\nmarkdown_extensions:\n  - pymdownx.highlight:\n      anchor_linenums: true\n  - pymdownx.inlinehilite\n  - pymdownx.snippets\n  - pymdownx.superfences:\n      custom_fences:\n        - name: mermaid\n          class: mermaid\n          format: !!python/name:pymdownx.superfences.fence_code_format\n  - admonition\n  - pymdownx.details\n  - attr_list\n  - md_in_html\n\nnav:\n  - In\u00edcio: README.md\n  - \u00cdndice: docs/INDEX_LLMs_Judge.md\n  - Quick Start: docs/QUICK_START_JUDGE.md\n  - Resumo Executivo: docs/RESUMO_EXECUTIVO_LLMs_Judge.md\n  - Estudo Completo: docs/LLMs_as_Judge_Study.md\n  - Guia de Deploy: docs/DEPLOYMENT_GUIDE.md\n  - Exemplos:\n    - Implementa\u00e7\u00e3o: examples/llm_judge_implementation.py\n    - Templates: examples/judge_prompts_templates.py\n    - Configura\u00e7\u00f5es: examples/judge_configs.yaml\n</code></pre>"},{"location":"DEPLOYMENT_GUIDE/#passo-3-instalar-dependencias","title":"Passo 3: Instalar Depend\u00eancias","text":"<p>Crie um arquivo <code>requirements-docs.txt</code>:</p> <pre><code>mkdocs&gt;=1.5.0\nmkdocs-material&gt;=9.0.0\nmkdocs-mermaid2-plugin&gt;=1.0.0\n</code></pre> <p>Instale:</p> <pre><code>pip install -r requirements-docs.txt\n</code></pre>"},{"location":"DEPLOYMENT_GUIDE/#passo-4-testar-localmente","title":"Passo 4: Testar Localmente","text":"<pre><code># Servir localmente\nmkdocs serve\n\n# Acesse: http://127.0.0.1:8000\n</code></pre>"},{"location":"DEPLOYMENT_GUIDE/#passo-5-configurar-github-actions","title":"Passo 5: Configurar GitHub Actions","text":"<p>Crie <code>.github/workflows/deploy.yml</code>:</p> <pre><code>name: Deploy Docs\n\non:\n  push:\n    branches:\n      - main\n    paths:\n      - 'docs/**'\n      - 'mkdocs.yml'\n      - '.github/workflows/deploy.yml'\n\npermissions:\n  contents: write\n\njobs:\n  deploy:\n    runs-on: ubuntu-latest\n    steps:\n      - uses: actions/checkout@v3\n\n      - name: Setup Python\n        uses: actions/setup-python@v4\n        with:\n          python-version: '3.11'\n\n      - name: Install dependencies\n        run: |\n          pip install -r requirements-docs.txt\n\n      - name: Build docs\n        run: mkdocs build\n\n      - name: Deploy to GitHub Pages\n        uses: peaceiris/actions-gh-pages@v3\n        with:\n          github_token: ${{ secrets.GITHUB_TOKEN }}\n          publish_dir: ./site\n</code></pre>"},{"location":"DEPLOYMENT_GUIDE/#passo-6-habilitar-github-pages","title":"Passo 6: Habilitar GitHub Pages","text":"<ol> <li>V\u00e1 em Settings do reposit\u00f3rio</li> <li>Pages \u2192 Source: Selecione GitHub Actions</li> <li>Fa\u00e7a um push para ativar o workflow</li> </ol>"},{"location":"DEPLOYMENT_GUIDE/#passo-7-deploy","title":"Passo 7: Deploy","text":"<pre><code>git add .\ngit commit -m \"docs: Configura MkDocs e GitHub Pages\"\ngit push\n</code></pre> <p>A documenta\u00e7\u00e3o estar\u00e1 dispon\u00edvel em: <code>https://flaviohbonfim.github.io/llm-as-a-judge-study</code></p>"},{"location":"DEPLOYMENT_GUIDE/#opcao-3-docusaurus-alternativa-moderna","title":"\ud83c\udfaf Op\u00e7\u00e3o 3: Docusaurus (Alternativa Moderna)","text":""},{"location":"DEPLOYMENT_GUIDE/#passo-1-instalar-docusaurus","title":"Passo 1: Instalar Docusaurus","text":"<pre><code>npx create-docusaurus@latest llms-judge-docs classic\ncd llms-judge-docs\n</code></pre>"},{"location":"DEPLOYMENT_GUIDE/#passo-2-copiar-documentos","title":"Passo 2: Copiar Documentos","text":"<pre><code># Copie os arquivos markdown (se necess\u00e1rio)\n# cp -r ../llm-as-a-judge-study/docs/* docs/\n</code></pre>"},{"location":"DEPLOYMENT_GUIDE/#passo-3-configurar","title":"Passo 3: Configurar","text":"<p>Edite <code>docusaurus.config.js</code> para incluir seus documentos.</p>"},{"location":"DEPLOYMENT_GUIDE/#passo-4-deploy-no-github-pages","title":"Passo 4: Deploy no GitHub Pages","text":"<pre><code>npm run deploy\n</code></pre>"},{"location":"DEPLOYMENT_GUIDE/#estrutura-recomendada-do-repositorio","title":"\ud83d\udcdd Estrutura Recomendada do Reposit\u00f3rio","text":"<pre><code>llm-as-a-judge-study/\n\u251c\u2500\u2500 .github/\n\u2502   \u2514\u2500\u2500 workflows/\n\u2502       \u2514\u2500\u2500 deploy.yml          # GitHub Actions (se usar MkDocs)\n\u251c\u2500\u2500 docs/\n\u2502   \u251c\u2500\u2500 README.md\n\u2502   \u251c\u2500\u2500 INDEX_LLMs_Judge.md\n\u2502   \u251c\u2500\u2500 QUICK_START_JUDGE.md\n\u2502   \u251c\u2500\u2500 RESUMO_EXECUTIVO_LLMs_Judge.md\n\u2502   \u251c\u2500\u2500 LLMs_as_Judge_Study.md\n\u2502   \u2514\u2500\u2500 DEPLOYMENT_GUIDE.md\n\u251c\u2500\u2500 examples/\n\u2502   \u251c\u2500\u2500 README_JUDGE.md\n\u2502   \u251c\u2500\u2500 llm_judge_implementation.py\n\u2502   \u251c\u2500\u2500 judge_prompts_templates.py\n\u2502   \u2514\u2500\u2500 judge_configs.yaml\n\u251c\u2500\u2500 README.md                   # README principal do reposit\u00f3rio\n\u251c\u2500\u2500 mkdocs.yml                  # Configura\u00e7\u00e3o MkDocs (se usar)\n\u2514\u2500\u2500 requirements-docs.txt       # Depend\u00eancias (se usar MkDocs)\n</code></pre>"},{"location":"DEPLOYMENT_GUIDE/#personalizacao","title":"\ud83c\udfa8 Personaliza\u00e7\u00e3o","text":""},{"location":"DEPLOYMENT_GUIDE/#gitbook","title":"GitBook","text":"<ul> <li>Acesse Settings \u2192 Appearance no GitBook</li> <li>Customize cores, logo, favicon</li> <li>Configure dom\u00ednio customizado (opcional)</li> </ul>"},{"location":"DEPLOYMENT_GUIDE/#mkdocs-material","title":"MkDocs Material","text":"<p>Edite <code>mkdocs.yml</code> para personalizar: - Cores e tema - Logo e favicon - Plugins adicionais - Navega\u00e7\u00e3o</p>"},{"location":"DEPLOYMENT_GUIDE/#atualizacoes-futuras","title":"\ud83d\udd04 Atualiza\u00e7\u00f5es Futuras","text":""},{"location":"DEPLOYMENT_GUIDE/#gitbook_1","title":"GitBook","text":"<pre><code># Simplesmente fa\u00e7a push\ngit add .\ngit commit -m \"docs: Atualiza documenta\u00e7\u00e3o\"\ngit push\n# GitBook atualiza automaticamente\n</code></pre>"},{"location":"DEPLOYMENT_GUIDE/#github-pages-mkdocs","title":"GitHub Pages + MkDocs","text":"<pre><code># Fa\u00e7a push normalmente\ngit add .\ngit commit -m \"docs: Atualiza documenta\u00e7\u00e3o\"\ngit push\n# GitHub Actions faz o deploy automaticamente\n</code></pre>"},{"location":"DEPLOYMENT_GUIDE/#comparacao-rapida","title":"\ud83d\udcca Compara\u00e7\u00e3o R\u00e1pida","text":"Recurso GitBook MkDocs Docusaurus Facilidade \u2b50\u2b50\u2b50\u2b50\u2b50 \u2b50\u2b50\u2b50 \u2b50\u2b50 Customiza\u00e7\u00e3o \u2b50\u2b50\u2b50 \u2b50\u2b50\u2b50\u2b50\u2b50 \u2b50\u2b50\u2b50\u2b50\u2b50 Custo Gr\u00e1tis* Gr\u00e1tis Gr\u00e1tis Sincroniza\u00e7\u00e3o Autom\u00e1tica Via CI/CD Via CI/CD Controle M\u00e9dio Total Total <p>*GitBook tem plano gratuito com limita\u00e7\u00f5es</p>"},{"location":"DEPLOYMENT_GUIDE/#checklist-final","title":"\u2705 Checklist Final","text":"<ul> <li>[ ] Reposit\u00f3rio criado no GitHub</li> <li>[ ] Arquivos commitados e push realizados</li> <li>[ ] Documenta\u00e7\u00e3o configurada (GitBook ou MkDocs)</li> <li>[ ] Testado localmente (se aplic\u00e1vel)</li> <li>[ ] Deploy realizado</li> <li>[ ] Link de acesso funcionando</li> <li>[ ] README.md atualizado com link</li> </ul>"},{"location":"DEPLOYMENT_GUIDE/#pronto","title":"\ud83c\udf89 Pronto!","text":"<p>Sua documenta\u00e7\u00e3o estar\u00e1 dispon\u00edvel publicamente e com visual profissional!</p> <p>Recomenda\u00e7\u00e3o: Comece com GitBook pela facilidade, depois migre para MkDocs se precisar de mais controle.</p> <p>D\u00favidas? Consulte: - GitBook Docs - MkDocs Material - GitHub Pages</p>"},{"location":"INDEX_LLMs_Judge/","title":"\ud83d\udcda \u00cdndice: Estudo sobre LLMs as a Judge","text":"<p>Este \u00edndice organiza todos os documentos e recursos relacionados ao estudo sobre LLMs as a Judge.</p>"},{"location":"INDEX_LLMs_Judge/#documentos-principais","title":"\ud83d\udcd6 Documentos Principais","text":""},{"location":"INDEX_LLMs_Judge/#0-guia-de-deploy","title":"0. Guia de Deploy \ud83d\ude80","text":"<p>Como publicar a documenta\u00e7\u00e3o no GitHub e visualizar como GitBook</p> <p>Conte\u00fado: - Op\u00e7\u00f5es de deploy (GitBook, MkDocs, Docusaurus) - Passo a passo completo - Configura\u00e7\u00e3o de GitHub Pages - Scripts de automa\u00e7\u00e3o</p> <p>Tempo estimado: 15 minutos N\u00edvel: Intermedi\u00e1rio</p>"},{"location":"INDEX_LLMs_Judge/#1-estudo-completo","title":"1. Estudo Completo","text":"<p>Documento principal com estudo profundo sobre o tema</p> <p>Conte\u00fado: - Introdu\u00e7\u00e3o ao conceito de LLMs as a Judge - An\u00e1lise comparativa de modelos LLM - Integra\u00e7\u00e3o com Google ADK - Integra\u00e7\u00e3o com Langfuse - Exemplos pr\u00e1ticos completos - M\u00e9tricas e benchmarks - Melhores pr\u00e1ticas - Casos de uso espec\u00edficos</p> <p>Tempo estimado de leitura: 45-60 minutos N\u00edvel: Avan\u00e7ado</p>"},{"location":"INDEX_LLMs_Judge/#2-resumo-executivo","title":"2. Resumo Executivo","text":"<p>Vis\u00e3o geral r\u00e1pida das principais conclus\u00f5es</p> <p>Conte\u00fado: - Principais conclus\u00f5es - Modelos recomendados - Tipos de avalia\u00e7\u00e3o - Recomenda\u00e7\u00f5es pr\u00e1ticas - M\u00e9tricas importantes</p> <p>Tempo estimado de leitura: 10 minutos N\u00edvel: Executivo/Intermedi\u00e1rio</p>"},{"location":"INDEX_LLMs_Judge/#3-quick-start-guide","title":"3. Quick Start Guide","text":"<p>Guia r\u00e1pido para come\u00e7ar em 5 minutos</p> <p>Conte\u00fado: - Configura\u00e7\u00e3o b\u00e1sica - Exemplos pr\u00e1ticos imediatos - Troubleshooting comum - Pr\u00f3ximos passos</p> <p>Tempo estimado de leitura: 5 minutos N\u00edvel: Iniciante</p>"},{"location":"INDEX_LLMs_Judge/#codigo-e-exemplos","title":"\ud83d\udcbb C\u00f3digo e Exemplos","text":""},{"location":"INDEX_LLMs_Judge/#4-implementacao-completa","title":"4. Implementa\u00e7\u00e3o Completa","text":"<p>Classes Python prontas para uso</p> <p>Inclui: - <code>LLMJudge</code>: Judge b\u00e1sico - <code>LangfuseLLMJudge</code>: Judge com integra\u00e7\u00e3o Langfuse - M\u00e9todos de avalia\u00e7\u00e3o completos - Tratamento de erros</p> <p>Uso: Importe e use diretamente em seu projeto</p>"},{"location":"INDEX_LLMs_Judge/#5-templates-de-prompts","title":"5. Templates de Prompts","text":"<p>Templates reutiliz\u00e1veis para diferentes tipos de avalia\u00e7\u00e3o</p> <p>Templates inclu\u00eddos: - Avalia\u00e7\u00e3o de trajet\u00f3ria - Avalia\u00e7\u00e3o de qualidade de resposta - Avalia\u00e7\u00e3o comparativa - Avalia\u00e7\u00e3o conversacional - Avalia\u00e7\u00e3o de c\u00f3digo - Avalia\u00e7\u00e3o RAG</p> <p>Uso: Importe templates e customize conforme necess\u00e1rio</p>"},{"location":"INDEX_LLMs_Judge/#6-configuracoes-recomendadas","title":"6. Configura\u00e7\u00f5es Recomendadas","text":"<p>Configura\u00e7\u00f5es YAML para diferentes cen\u00e1rios</p> <p>Inclui: - Configura\u00e7\u00f5es de modelos - Crit\u00e9rios de avalia\u00e7\u00e3o - Escalas de pontua\u00e7\u00e3o - Otimiza\u00e7\u00f5es de custo - Configura\u00e7\u00f5es de robustez</p> <p>Uso: Carregue configura\u00e7\u00f5es no seu c\u00f3digo</p>"},{"location":"INDEX_LLMs_Judge/#7-readme-dos-exemplos","title":"7. README dos Exemplos","text":"<p>Documenta\u00e7\u00e3o dos exemplos pr\u00e1ticos</p> <p>Conte\u00fado: - Como usar cada exemplo - Integra\u00e7\u00e3o com ADK - Casos de uso espec\u00edficos</p>"},{"location":"INDEX_LLMs_Judge/#roteiro-de-leitura","title":"\ud83d\uddfa\ufe0f Roteiro de Leitura","text":""},{"location":"INDEX_LLMs_Judge/#para-iniciantes","title":"Para Iniciantes","text":"<ol> <li>\u2705 Quick Start Guide - Comece aqui!</li> <li>\u2705 Resumo Executivo - Entenda o contexto</li> <li>\u2705 Implementa\u00e7\u00e3o Completa - Veja o c\u00f3digo</li> <li>\u2705 Estudo Completo - Aprofunde-se</li> </ol>"},{"location":"INDEX_LLMs_Judge/#para-desenvolvedores","title":"Para Desenvolvedores","text":"<ol> <li>\u2705 Quick Start Guide - Setup r\u00e1pido</li> <li>\u2705 Implementa\u00e7\u00e3o Completa - Entenda a implementa\u00e7\u00e3o</li> <li>\u2705 Templates de Prompts - Use templates</li> <li>\u2705 Estudo Completo - Se\u00e7\u00e3o de integra\u00e7\u00e3o e melhores pr\u00e1ticas</li> </ol>"},{"location":"INDEX_LLMs_Judge/#para-gestoresarquiteto","title":"Para Gestores/Arquiteto","text":"<ol> <li>\u2705 Resumo Executivo - Vis\u00e3o estrat\u00e9gica</li> <li>\u2705 Estudo Completo - Se\u00e7\u00f5es 1, 2, 9 (Conclus\u00f5es)</li> <li>\u2705 Configura\u00e7\u00f5es Recomendadas - Entenda op\u00e7\u00f5es</li> </ol>"},{"location":"INDEX_LLMs_Judge/#topicos-por-documento","title":"\ud83d\udccb T\u00f3picos por Documento","text":""},{"location":"INDEX_LLMs_Judge/#conceitos-fundamentais","title":"Conceitos Fundamentais","text":"<ul> <li>\u2705 O que s\u00e3o LLMs as a Judge</li> <li>\u2705 Por que usar LLMs como Judge</li> <li>\u2705 Tipos de avalia\u00e7\u00e3o</li> <li>\ud83d\udcc4 Documento: Estudo Completo - Se\u00e7\u00e3o 1</li> </ul>"},{"location":"INDEX_LLMs_Judge/#modelos-e-selecao","title":"Modelos e Sele\u00e7\u00e3o","text":"<ul> <li>\u2705 An\u00e1lise comparativa de modelos</li> <li>\u2705 Crit\u00e9rios de sele\u00e7\u00e3o</li> <li>\u2705 Recomenda\u00e7\u00f5es por caso de uso</li> <li>\ud83d\udcc4 Documento: Estudo Completo - Se\u00e7\u00e3o 2</li> <li>\ud83d\udcc4 Resumo: Resumo Executivo - Modelos Recomendados</li> </ul>"},{"location":"INDEX_LLMs_Judge/#integracao-tecnica","title":"Integra\u00e7\u00e3o T\u00e9cnica","text":"<ul> <li>\u2705 Integra\u00e7\u00e3o com Google ADK</li> <li>\u2705 Integra\u00e7\u00e3o com Langfuse</li> <li>\u2705 Exemplos de c\u00f3digo</li> <li>\ud83d\udcc4 Documento: Estudo Completo - Se\u00e7\u00f5es 3 e 4</li> <li>\ud83d\udcc4 C\u00f3digo: Implementa\u00e7\u00e3o Completa</li> </ul>"},{"location":"INDEX_LLMs_Judge/#implementacao-pratica","title":"Implementa\u00e7\u00e3o Pr\u00e1tica","text":"<ul> <li>\u2705 Setup e configura\u00e7\u00e3o</li> <li>\u2705 Exemplos de uso</li> <li>\u2705 Templates de prompts</li> <li>\ud83d\udcc4 Guia: Quick Start Guide</li> <li>\ud83d\udcc4 C\u00f3digo: Implementa\u00e7\u00e3o Completa</li> <li>\ud83d\udcc4 Templates: Templates de Prompts</li> </ul>"},{"location":"INDEX_LLMs_Judge/#metricas-e-avaliacao","title":"M\u00e9tricas e Avalia\u00e7\u00e3o","text":"<ul> <li>\u2705 M\u00e9tricas de qualidade do judge</li> <li>\u2705 Benchmarks recomendados</li> <li>\u2705 Correla\u00e7\u00e3o com avalia\u00e7\u00e3o humana</li> <li>\ud83d\udcc4 Documento: Estudo Completo - Se\u00e7\u00e3o 6</li> </ul>"},{"location":"INDEX_LLMs_Judge/#melhores-praticas","title":"Melhores Pr\u00e1ticas","text":"<ul> <li>\u2705 Design de prompts</li> <li>\u2705 Otimiza\u00e7\u00e3o de custo</li> <li>\u2705 Tratamento de erros</li> <li>\u2705 Calibra\u00e7\u00e3o</li> <li>\ud83d\udcc4 Documento: Estudo Completo - Se\u00e7\u00e3o 7</li> </ul>"},{"location":"INDEX_LLMs_Judge/#casos-de-uso","title":"Casos de Uso","text":"<ul> <li>\u2705 Agentes conversacionais</li> <li>\u2705 Agentes de c\u00f3digo</li> <li>\u2705 Agentes RAG</li> <li>\ud83d\udcc4 Documento: Estudo Completo - Se\u00e7\u00e3o 8</li> </ul>"},{"location":"INDEX_LLMs_Judge/#busca-rapida","title":"\ud83d\udd0d Busca R\u00e1pida","text":""},{"location":"INDEX_LLMs_Judge/#como-comecar","title":"\"Como come\u00e7ar?\"","text":"<p>\u2192 Quick Start Guide</p>"},{"location":"INDEX_LLMs_Judge/#qual-modelo-usar","title":"\"Qual modelo usar?\"","text":"<p>\u2192 Resumo Executivo - Modelos Recomendados \u2192 Estudo Completo - Se\u00e7\u00e3o 2</p>"},{"location":"INDEX_LLMs_Judge/#como-integrar-com-adk","title":"\"Como integrar com ADK?\"","text":"<p>\u2192 Estudo Completo - Se\u00e7\u00e3o 3 \u2192 Implementa\u00e7\u00e3o Completa</p>"},{"location":"INDEX_LLMs_Judge/#como-integrar-com-langfuse","title":"\"Como integrar com Langfuse?\"","text":"<p>\u2192 Estudo Completo - Se\u00e7\u00e3o 4 \u2192 Implementa\u00e7\u00e3o Completa - Classe <code>LangfuseLLMJudge</code></p>"},{"location":"INDEX_LLMs_Judge/#como-avaliar-trajetoria","title":"\"Como avaliar trajet\u00f3ria?\"","text":"<p>\u2192 Estudo Completo - Se\u00e7\u00e3o 1.3.1 \u2192 Templates de Prompts - <code>trajectory_evaluation</code></p>"},{"location":"INDEX_LLMs_Judge/#como-avaliar-qualidade-de-resposta","title":"\"Como avaliar qualidade de resposta?\"","text":"<p>\u2192 Estudo Completo - Se\u00e7\u00e3o 1.3.2 \u2192 Templates de Prompts - <code>response_quality</code></p>"},{"location":"INDEX_LLMs_Judge/#como-comparar-multiplas-respostas","title":"\"Como comparar m\u00faltiplas respostas?\"","text":"<p>\u2192 Estudo Completo - Se\u00e7\u00e3o 1.3.3 \u2192 Templates de Prompts - <code>comparative_evaluation</code></p>"},{"location":"INDEX_LLMs_Judge/#como-otimizar-custos","title":"\"Como otimizar custos?\"","text":"<p>\u2192 Estudo Completo - Se\u00e7\u00e3o 7.2 \u2192 Configura\u00e7\u00f5es Recomendadas - <code>cost_optimization</code></p>"},{"location":"INDEX_LLMs_Judge/#quais-sao-as-melhores-praticas","title":"\"Quais s\u00e3o as melhores pr\u00e1ticas?\"","text":"<p>\u2192 Estudo Completo - Se\u00e7\u00e3o 7</p>"},{"location":"INDEX_LLMs_Judge/#como-publicar-no-githubgitbook","title":"\"Como publicar no GitHub/GitBook?\"","text":"<p>\u2192 Guia de Deploy</p>"},{"location":"INDEX_LLMs_Judge/#estrutura-de-arquivos","title":"\ud83d\udcca Estrutura de Arquivos","text":"<pre><code>llm-as-a-judge-study/\n\u251c\u2500\u2500 docs/\n\u2502   \u251c\u2500\u2500 LLMs_as_Judge_Study.md          # Estudo completo (principal)\n\u2502   \u251c\u2500\u2500 RESUMO_EXECUTIVO_LLMs_Judge.md  # Resumo executivo\n\u2502   \u251c\u2500\u2500 QUICK_START_JUDGE.md            # Guia r\u00e1pido\n\u2502   \u2514\u2500\u2500 INDEX_LLMs_Judge.md             # Este arquivo\n\u2502\n\u2514\u2500\u2500 examples/\n    \u251c\u2500\u2500 llm_judge_implementation.py     # Implementa\u00e7\u00e3o completa\n    \u251c\u2500\u2500 judge_prompts_templates.py      # Templates de prompts\n    \u251c\u2500\u2500 judge_configs.yaml              # Configura\u00e7\u00f5es\n    \u2514\u2500\u2500 README_JUDGE.md                 # Documenta\u00e7\u00e3o dos exemplos\n</code></pre>"},{"location":"INDEX_LLMs_Judge/#proximos-passos-recomendados","title":"\ud83c\udfaf Pr\u00f3ximos Passos Recomendados","text":"<ol> <li>Leia o Quick Start \u2192 Configure ambiente b\u00e1sico</li> <li>Teste os Exemplos \u2192 Execute c\u00f3digo de exemplo</li> <li>Leia o Resumo Executivo \u2192 Entenda recomenda\u00e7\u00f5es</li> <li>Estude a Implementa\u00e7\u00e3o \u2192 Entenda c\u00f3digo detalhado</li> <li>Leia o Estudo Completo \u2192 Aprofunde-se no tema</li> <li>Adapte para Seu Caso \u2192 Customize para suas necessidades</li> </ol>"},{"location":"INDEX_LLMs_Judge/#suporte","title":"\ud83d\udcde Suporte","text":"<ul> <li>D\u00favidas sobre conceitos: Consulte Estudo Completo</li> <li>D\u00favidas sobre c\u00f3digo: Consulte Implementa\u00e7\u00e3o Completa</li> <li>D\u00favidas sobre uso: Consulte Quick Start Guide</li> </ul> <p>\u00daltima atualiza\u00e7\u00e3o: 2024 Vers\u00e3o: 1.0 Status: \u2705 Completo</p>"},{"location":"LLMs_as_Judge_Study/","title":"\ud83c\udfaf Estudo Profundo: LLMs as a Judge","text":""},{"location":"LLMs_as_Judge_Study/#identificando-os-melhores-tipos-de-llms-para-avaliacao-de-agentes","title":"Identificando os Melhores Tipos de LLMs para Avalia\u00e7\u00e3o de Agentes","text":"<p>Data: 2024 Contexto: Projetos Python com Google ADK e Langfuse Objetivo: Identificar os melhores tipos de LLMs para atuar como ju\u00edzes na avalia\u00e7\u00e3o de agentes de IA</p>"},{"location":"LLMs_as_Judge_Study/#sumario-executivo","title":"\ud83d\udccb Sum\u00e1rio Executivo","text":"<p>Este documento apresenta um estudo abrangente sobre o uso de Large Language Models (LLMs) como ju\u00edzes (judges) na avalia\u00e7\u00e3o de agentes de IA. O estudo foca em:</p> <ul> <li>Conceito de LLMs as a Judge: Modelos que avaliam a qualidade de respostas, trajet\u00f3rias e comportamento de agentes</li> <li>Tipos de Avalia\u00e7\u00e3o: Trajet\u00f3ria de ferramentas, qualidade de resposta, comportamento do agente</li> <li>Modelos Recomendados: An\u00e1lise comparativa de diferentes LLMs para fun\u00e7\u00e3o de judge</li> <li>Integra\u00e7\u00e3o Pr\u00e1tica: Como integrar judges com Google ADK e Langfuse</li> <li>M\u00e9tricas e Benchmarks: Como medir a efic\u00e1cia dos judges</li> <li>Melhores Pr\u00e1ticas: Padr\u00f5es e recomenda\u00e7\u00f5es para implementa\u00e7\u00e3o</li> </ul>"},{"location":"LLMs_as_Judge_Study/#1-introducao-ao-conceito-llms-as-a-judge","title":"1. Introdu\u00e7\u00e3o ao Conceito: LLMs as a Judge","text":""},{"location":"LLMs_as_Judge_Study/#11-o-que-sao-llms-as-a-judge","title":"1.1 O que s\u00e3o LLMs as a Judge?","text":"<p>LLMs as a Judge \u00e9 uma t\u00e9cnica onde um modelo de linguagem grande \u00e9 usado para avaliar a qualidade, corre\u00e7\u00e3o e adequa\u00e7\u00e3o de respostas geradas por outros modelos ou agentes. Em vez de usar m\u00e9tricas tradicionais baseadas em regras ou ground truth humano, o judge LLM atua como um avaliador inteligente que pode:</p> <ul> <li>Avaliar a qualidade sem\u00e2ntica de respostas</li> <li>Comparar m\u00faltiplas respostas e ranquear</li> <li>Avaliar trajet\u00f3rias de agentes (sequ\u00eancia de a\u00e7\u00f5es)</li> <li>Detectar problemas de seguran\u00e7a, alinhamento ou qualidade</li> <li>Fornecer feedback estruturado e explic\u00e1vel</li> </ul>"},{"location":"LLMs_as_Judge_Study/#12-por-que-usar-llms-como-judge","title":"1.2 Por que usar LLMs como Judge?","text":""},{"location":"LLMs_as_Judge_Study/#vantagens","title":"Vantagens:","text":"<ol> <li>Escalabilidade: Avalia milhares de respostas automaticamente</li> <li>Consist\u00eancia: Aplica os mesmos crit\u00e9rios de avalia\u00e7\u00e3o</li> <li>Custo: Mais barato que avalia\u00e7\u00e3o humana em larga escala</li> <li>Velocidade: Avalia\u00e7\u00f5es em tempo real ou quase real</li> <li>Flexibilidade: Pode avaliar m\u00faltiplos aspectos simultaneamente</li> <li>Explicabilidade: Pode fornecer justificativas para suas avalia\u00e7\u00f5es</li> </ol>"},{"location":"LLMs_as_Judge_Study/#desafios","title":"Desafios:","text":"<ol> <li>Vi\u00e9s do Modelo: O judge pode ter seus pr\u00f3prios vieses</li> <li>Alinhamento: Necessidade de garantir que o judge avalia o que realmente importa</li> <li>Consist\u00eancia: Pode haver varia\u00e7\u00e3o entre avalia\u00e7\u00f5es</li> <li>Custo Computacional: Requer chamadas adicionais a LLMs</li> <li>Ground Truth: Ainda pode ser necess\u00e1rio valida\u00e7\u00e3o humana</li> </ol>"},{"location":"LLMs_as_Judge_Study/#13-tipos-de-avaliacao-com-llms-as-judge","title":"1.3 Tipos de Avalia\u00e7\u00e3o com LLMs as Judge","text":""},{"location":"LLMs_as_Judge_Study/#131-avaliacao-de-trajetoria-trajectory-evaluation","title":"1.3.1 Avalia\u00e7\u00e3o de Trajet\u00f3ria (Trajectory Evaluation)","text":"<p>Avalia a sequ\u00eancia de a\u00e7\u00f5es que o agente tomou:</p> <ul> <li>Ordem das a\u00e7\u00f5es: As a\u00e7\u00f5es foram executadas na ordem correta?</li> <li>Ferramentas utilizadas: O agente usou as ferramentas apropriadas?</li> <li>Efici\u00eancia: O agente tomou o caminho mais eficiente?</li> <li>Completude: Todas as a\u00e7\u00f5es necess\u00e1rias foram executadas?</li> </ul> <p>Exemplo de Prompt para Judge:</p> <pre><code>TRAJECTORY_EVALUATION_PROMPT = \"\"\"\nVoc\u00ea \u00e9 um juiz especializado em avaliar trajet\u00f3rias de agentes de IA.\n\nTrajet\u00f3ria Esperada: {expected_trajectory}\nTrajet\u00f3ria Real: {actual_trajectory}\n\nAvalie:\n1. As a\u00e7\u00f5es foram executadas na ordem correta? (0-1)\n2. Todas as a\u00e7\u00f5es necess\u00e1rias foram executadas? (0-1)\n3. Alguma a\u00e7\u00e3o desnecess\u00e1ria foi executada? (0-1)\n4. A trajet\u00f3ria foi eficiente? (0-1)\n\nForne\u00e7a uma pontua\u00e7\u00e3o geral de 0-1 e uma justificativa detalhada.\n\"\"\"\n</code></pre>"},{"location":"LLMs_as_Judge_Study/#132-avaliacao-de-qualidade-de-resposta-response-quality-evaluation","title":"1.3.2 Avalia\u00e7\u00e3o de Qualidade de Resposta (Response Quality Evaluation)","text":"<p>Avalia a qualidade da resposta final do agente:</p> <ul> <li>Corre\u00e7\u00e3o: A resposta est\u00e1 factualmente correta?</li> <li>Relev\u00e2ncia: A resposta responde \u00e0 pergunta do usu\u00e1rio?</li> <li>Completude: A resposta est\u00e1 completa?</li> <li>Clareza: A resposta \u00e9 clara e bem estruturada?</li> <li>Seguran\u00e7a: A resposta \u00e9 segura e apropriada?</li> </ul> <p>Exemplo de Prompt para Judge:</p> <pre><code>RESPONSE_QUALITY_PROMPT = \"\"\"\nVoc\u00ea \u00e9 um juiz especializado em avaliar respostas de agentes de IA.\n\nPergunta do Usu\u00e1rio: {user_query}\nResposta do Agente: {agent_response}\nContexto: {context}\n\nAvalie a resposta em:\n1. Corre\u00e7\u00e3o factual (0-1)\n2. Relev\u00e2ncia \u00e0 pergunta (0-1)\n3. Completude (0-1)\n4. Clareza e estrutura (0-1)\n5. Seguran\u00e7a e apropria\u00e7\u00e3o (0-1)\n\nForne\u00e7a uma pontua\u00e7\u00e3o geral de 0-1 e feedback detalhado.\n\"\"\"\n</code></pre>"},{"location":"LLMs_as_Judge_Study/#133-avaliacao-comparativa-comparative-evaluation","title":"1.3.3 Avalia\u00e7\u00e3o Comparativa (Comparative Evaluation)","text":"<p>Compara m\u00faltiplas respostas e ranqueia:</p> <ul> <li>Ranking: Qual resposta \u00e9 melhor?</li> <li>Diferen\u00e7as: Quais s\u00e3o as diferen\u00e7as principais?</li> <li>Trade-offs: Quais s\u00e3o os pr\u00f3s e contras de cada resposta?</li> </ul> <p>Exemplo de Prompt para Judge:</p> <pre><code>COMPARATIVE_EVALUATION_PROMPT = \"\"\"\nVoc\u00ea \u00e9 um juiz especializado em comparar respostas de agentes.\n\nPergunta: {user_query}\nResposta A: {response_a}\nResposta B: {response_b}\n\nCompare as respostas e:\n1. Identifique qual \u00e9 melhor (A ou B)\n2. Forne\u00e7a uma pontua\u00e7\u00e3o relativa (0-1 para cada)\n3. Liste os pontos fortes e fracos de cada resposta\n4. Explique sua decis\u00e3o\n\"\"\"\n</code></pre>"},{"location":"LLMs_as_Judge_Study/#134-avaliacao-de-comportamento-behavioral-evaluation","title":"1.3.4 Avalia\u00e7\u00e3o de Comportamento (Behavioral Evaluation)","text":"<p>Avalia o comportamento geral do agente:</p> <ul> <li>Alinhamento: O agente seguiu as instru\u00e7\u00f5es?</li> <li>\u00c9tica: O comportamento foi \u00e9tico?</li> <li>Robustez: O agente lidou bem com edge cases?</li> <li>Consist\u00eancia: O comportamento foi consistente?</li> </ul>"},{"location":"LLMs_as_Judge_Study/#2-modelos-llm-adequados-para-funcao-de-judge","title":"2. Modelos LLM Adequados para Fun\u00e7\u00e3o de Judge","text":""},{"location":"LLMs_as_Judge_Study/#21-criterios-para-selecao-de-judge-llm","title":"2.1 Crit\u00e9rios para Sele\u00e7\u00e3o de Judge LLM","text":"<p>Ao escolher um LLM para fun\u00e7\u00e3o de judge, considere:</p> <ol> <li>Capacidade de Racioc\u00ednio: Precisa entender nuances e contexto</li> <li>Consist\u00eancia: Deve fornecer avalia\u00e7\u00f5es consistentes</li> <li>Capacidade de Seguir Instru\u00e7\u00f5es: Deve seguir prompts de avalia\u00e7\u00e3o precisamente</li> <li>Custo: Deve ser economicamente vi\u00e1vel para uso em escala</li> <li>Lat\u00eancia: Deve ser r\u00e1pido o suficiente para uso em produ\u00e7\u00e3o</li> <li>Disponibilidade: Deve estar dispon\u00edvel atrav\u00e9s de APIs confi\u00e1veis</li> <li>Capacidade de Output Estruturado: Deve poder fornecer avalia\u00e7\u00f5es estruturadas</li> </ol>"},{"location":"LLMs_as_Judge_Study/#22-analise-comparativa-de-modelos","title":"2.2 An\u00e1lise Comparativa de Modelos","text":""},{"location":"LLMs_as_Judge_Study/#221-modelos-gpt-openai","title":"2.2.1 Modelos GPT (OpenAI)","text":"<p>GPT-4 Turbo / GPT-4o - \u2705 Excelente capacidade de racioc\u00ednio - \u2705 Alta consist\u00eancia - \u2705 Suporte a JSON mode para outputs estruturados - \u2705 Boa capacidade de seguir instru\u00e7\u00f5es complexas - \u26a0\ufe0f Custo mais alto - \u26a0\ufe0f Lat\u00eancia moderada</p> <p>GPT-3.5 Turbo - \u2705 Custo mais baixo - \u2705 Lat\u00eancia baixa - \u2705 Boa capacidade de racioc\u00ednio - \u26a0\ufe0f Menos consistente que GPT-4 - \u26a0\ufe0f Pode ter dificuldade com avalia\u00e7\u00f5es muito complexas</p> <p>Recomenda\u00e7\u00e3o: GPT-4o para avalia\u00e7\u00f5es cr\u00edticas, GPT-3.5 Turbo para avalia\u00e7\u00f5es em larga escala.</p>"},{"location":"LLMs_as_Judge_Study/#222-modelos-gemini-google","title":"2.2.2 Modelos Gemini (Google)","text":"<p>Gemini 2.0 Flash - \u2705 Excelente custo-benef\u00edcio - \u2705 Lat\u00eancia muito baixa - \u2705 Boa capacidade de racioc\u00ednio - \u2705 Integra\u00e7\u00e3o nativa com Google ADK - \u26a0\ufe0f Pode ser menos consistente que GPT-4 em casos complexos</p> <p>Gemini 2.0 Pro - \u2705 Excelente capacidade de racioc\u00ednio - \u2705 Alta consist\u00eancia - \u2705 Suporte a contexto muito longo - \u26a0\ufe0f Custo mais alto que Flash - \u26a0\ufe0f Lat\u00eancia maior</p> <p>Recomenda\u00e7\u00e3o: Gemini 2.0 Flash para maioria dos casos, Gemini 2.0 Pro para avalia\u00e7\u00f5es muito complexas.</p>"},{"location":"LLMs_as_Judge_Study/#223-modelos-claude-anthropic","title":"2.2.3 Modelos Claude (Anthropic)","text":"<p>Claude 3.5 Sonnet - \u2705 Excelente capacidade de racioc\u00ednio - \u2705 Muito consistente - \u2705 Excelente em an\u00e1lise detalhada - \u2705 Suporte a contexto muito longo - \u26a0\ufe0f Custo moderado-alto - \u26a0\ufe0f Lat\u00eancia moderada</p> <p>Claude 3 Haiku - \u2705 Custo muito baixo - \u2705 Lat\u00eancia muito baixa - \u2705 Boa capacidade de racioc\u00ednio - \u26a0\ufe0f Menos consistente que Sonnet</p> <p>Recomenda\u00e7\u00e3o: Claude 3.5 Sonnet para avalia\u00e7\u00f5es cr\u00edticas, Claude 3 Haiku para avalia\u00e7\u00f5es em larga escala.</p>"},{"location":"LLMs_as_Judge_Study/#224-modelos-open-source","title":"2.2.4 Modelos Open Source","text":"<p>Llama 3.1 70B / 405B - \u2705 Custo muito baixo (self-hosted) - \u2705 Controle total sobre o modelo - \u2705 Sem limites de rate - \u26a0\ufe0f Requer infraestrutura pr\u00f3pria - \u26a0\ufe0f Pode ser menos consistente que modelos comerciais - \u26a0\ufe0f Requer fine-tuning para melhor performance</p> <p>Mixtral 8x7B / 8x22B - \u2705 Custo muito baixo (self-hosted) - \u2705 Boa capacidade de racioc\u00ednio - \u26a0\ufe0f Requer infraestrutura pr\u00f3pria - \u26a0\ufe0f Pode precisar de fine-tuning</p> <p>Recomenda\u00e7\u00e3o: Para organiza\u00e7\u00f5es com infraestrutura adequada e necessidade de controle total.</p>"},{"location":"LLMs_as_Judge_Study/#23-tabela-comparativa-resumida","title":"2.3 Tabela Comparativa Resumida","text":"Modelo Custo Lat\u00eancia Racioc\u00ednio Consist\u00eancia Recomenda\u00e7\u00e3o GPT-4o Alto M\u00e9dia \u2b50\u2b50\u2b50\u2b50\u2b50 \u2b50\u2b50\u2b50\u2b50\u2b50 Cr\u00edtico GPT-3.5 Turbo Baixo Baixa \u2b50\u2b50\u2b50\u2b50 \u2b50\u2b50\u2b50\u2b50 Larga escala Gemini 2.0 Flash Muito Baixo Muito Baixa \u2b50\u2b50\u2b50\u2b50 \u2b50\u2b50\u2b50\u2b50 Recomendado Gemini 2.0 Pro M\u00e9dio M\u00e9dia \u2b50\u2b50\u2b50\u2b50\u2b50 \u2b50\u2b50\u2b50\u2b50\u2b50 Complexo Claude 3.5 Sonnet M\u00e9dio-Alto M\u00e9dia \u2b50\u2b50\u2b50\u2b50\u2b50 \u2b50\u2b50\u2b50\u2b50\u2b50 Cr\u00edtico Claude 3 Haiku Muito Baixo Muito Baixa \u2b50\u2b50\u2b50\u2b50 \u2b50\u2b50\u2b50\u2b50 Larga escala Llama 3.1 70B Muito Baixo* M\u00e9dia* \u2b50\u2b50\u2b50\u2b50 \u2b50\u2b50\u2b50 Self-hosted <p>*Custo e lat\u00eancia dependem da infraestrutura pr\u00f3pria</p>"},{"location":"LLMs_as_Judge_Study/#24-recomendacoes-por-caso-de-uso","title":"2.4 Recomenda\u00e7\u00f5es por Caso de Uso","text":""},{"location":"LLMs_as_Judge_Study/#para-avaliacoes-em-tempo-real-producao","title":"Para Avalia\u00e7\u00f5es em Tempo Real (Produ\u00e7\u00e3o)","text":"<ul> <li>Prim\u00e1rio: Gemini 2.0 Flash ou Claude 3 Haiku</li> <li>Alternativa: GPT-3.5 Turbo</li> </ul>"},{"location":"LLMs_as_Judge_Study/#para-avaliacoes-criticas-qualidade-maxima","title":"Para Avalia\u00e7\u00f5es Cr\u00edticas (Qualidade M\u00e1xima)","text":"<ul> <li>Prim\u00e1rio: GPT-4o ou Claude 3.5 Sonnet</li> <li>Alternativa: Gemini 2.0 Pro</li> </ul>"},{"location":"LLMs_as_Judge_Study/#para-avaliacoes-em-larga-escala-batch","title":"Para Avalia\u00e7\u00f5es em Larga Escala (Batch)","text":"<ul> <li>Prim\u00e1rio: Gemini 2.0 Flash ou Claude 3 Haiku</li> <li>Alternativa: GPT-3.5 Turbo</li> </ul>"},{"location":"LLMs_as_Judge_Study/#para-avaliacoes-com-alto-volume-e-baixo-custo","title":"Para Avalia\u00e7\u00f5es com Alto Volume e Baixo Custo","text":"<ul> <li>Prim\u00e1rio: Modelos open source self-hosted (Llama 3.1)</li> <li>Alternativa: Gemini 2.0 Flash</li> </ul>"},{"location":"LLMs_as_Judge_Study/#3-integracao-com-google-adk","title":"3. Integra\u00e7\u00e3o com Google ADK","text":""},{"location":"LLMs_as_Judge_Study/#31-arquitetura-de-integracao","title":"3.1 Arquitetura de Integra\u00e7\u00e3o","text":"<p>O Google ADK j\u00e1 possui suporte nativo para avalia\u00e7\u00e3o atrav\u00e9s do <code>AgentEvaluator</code>. Podemos estender isso para usar LLMs as Judge:</p> <pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502   Agent ADK     \u2502\n\u2502   (Sob Teste)   \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n         \u2502\n         \u25bc\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502  AgentEvaluator \u2502\n\u2502   (ADK Native)  \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n         \u2502\n         \u25bc\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502  LLM Judge      \u2502\n\u2502  (Customizado)  \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n         \u2502\n         \u25bc\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502   Langfuse      \u2502\n\u2502  (Tracing/Log)  \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"LLMs_as_Judge_Study/#32-implementacao-de-judge-com-adk","title":"3.2 Implementa\u00e7\u00e3o de Judge com ADK","text":""},{"location":"LLMs_as_Judge_Study/#321-criando-um-judge-agent","title":"3.2.1 Criando um Judge Agent","text":"<pre><code>from google.adk import Agent\nfrom typing import Dict, Any, List\nimport json\n\n# Judge Agent especializado em avalia\u00e7\u00e3o\njudge_agent = Agent(\n    name=\"evaluation_judge\",\n    description=\"Especialista em avaliar qualidade de respostas e trajet\u00f3rias de agentes\",\n    instruction=\"\"\"\n    Voc\u00ea \u00e9 um juiz especializado em avaliar agentes de IA.\n\n    Sua tarefa \u00e9 avaliar:\n    1. A qualidade da resposta do agente\n    2. A trajet\u00f3ria de a\u00e7\u00f5es tomadas\n    3. A adequa\u00e7\u00e3o ao contexto e requisitos\n\n    Sempre forne\u00e7a:\n    - Uma pontua\u00e7\u00e3o num\u00e9rica de 0-1\n    - Uma justificativa detalhada\n    - Pontos fortes e fracos identificados\n    - Recomenda\u00e7\u00f5es de melhoria\n\n    Formate sua resposta como JSON estruturado.\n    \"\"\",\n    model=\"gemini-2.0-flash\",  # Ou outro modelo adequado\n)\n</code></pre>"},{"location":"LLMs_as_Judge_Study/#322-classe-de-judge-customizada","title":"3.2.2 Classe de Judge Customizada","text":"<pre><code>from google.adk import Runner, Session\nfrom typing import Optional, Dict, Any\nimport json\n\nclass LLMJudge:\n    \"\"\"Judge usando LLM para avaliar agentes ADK\"\"\"\n\n    def __init__(\n        self,\n        judge_agent: Agent,\n        runner: Runner,\n        evaluation_criteria: Dict[str, str]\n    ):\n        self.judge_agent = judge_agent\n        self.runner = runner\n        self.criteria = evaluation_criteria\n\n    async def evaluate_trajectory(\n        self,\n        expected_trajectory: List[str],\n        actual_trajectory: List[str],\n        context: Optional[Dict[str, Any]] = None\n    ) -&gt; Dict[str, Any]:\n        \"\"\"Avalia a trajet\u00f3ria de a\u00e7\u00f5es do agente\"\"\"\n\n        prompt = f\"\"\"\n        Avalie a trajet\u00f3ria do agente:\n\n        Trajet\u00f3ria Esperada: {json.dumps(expected_trajectory, ensure_ascii=False)}\n        Trajet\u00f3ria Real: {json.dumps(actual_trajectory, ensure_ascii=False)}\n        Contexto: {json.dumps(context or {}, ensure_ascii=False)}\n\n        Crit\u00e9rios de Avalia\u00e7\u00e3o:\n        {json.dumps(self.criteria, ensure_ascii=False, indent=2)}\n\n        Forne\u00e7a uma avalia\u00e7\u00e3o em JSON com:\n        - score: pontua\u00e7\u00e3o de 0-1\n        - order_match: as a\u00e7\u00f5es est\u00e3o na ordem correta? (0-1)\n        - completeness: todas as a\u00e7\u00f5es necess\u00e1rias foram executadas? (0-1)\n        - efficiency: a trajet\u00f3ria foi eficiente? (0-1)\n        - justification: justificativa detalhada\n        - strengths: pontos fortes\n        - weaknesses: pontos fracos\n        \"\"\"\n\n        session = Session()\n        response = await self.runner.run(\n            agent=self.judge_agent,\n            session=session,\n            user_content=prompt\n        )\n\n        # Parse da resposta JSON\n        try:\n            evaluation = json.loads(response.content)\n            return evaluation\n        except json.JSONDecodeError:\n            # Fallback: tentar extrair JSON da resposta\n            return self._extract_json_from_response(response.content)\n\n    async def evaluate_response(\n        self,\n        user_query: str,\n        agent_response: str,\n        expected_response: Optional[str] = None,\n        context: Optional[Dict[str, Any]] = None\n    ) -&gt; Dict[str, Any]:\n        \"\"\"Avalia a qualidade da resposta do agente\"\"\"\n\n        prompt = f\"\"\"\n        Avalie a resposta do agente:\n\n        Pergunta do Usu\u00e1rio: {user_query}\n        Resposta do Agente: {agent_response}\n        Resposta Esperada (refer\u00eancia): {expected_response or \"N/A\"}\n        Contexto: {json.dumps(context or {}, ensure_ascii=False, indent=2)}\n\n        Crit\u00e9rios de Avalia\u00e7\u00e3o:\n        {json.dumps(self.criteria, ensure_ascii=False, indent=2)}\n\n        Forne\u00e7a uma avalia\u00e7\u00e3o em JSON com:\n        - score: pontua\u00e7\u00e3o geral de 0-1\n        - correctness: corre\u00e7\u00e3o factual (0-1)\n        - relevance: relev\u00e2ncia \u00e0 pergunta (0-1)\n        - completeness: completude (0-1)\n        - clarity: clareza e estrutura (0-1)\n        - safety: seguran\u00e7a e apropria\u00e7\u00e3o (0-1)\n        - justification: justificativa detalhada\n        - strengths: pontos fortes\n        - weaknesses: pontos fracos\n        - recommendations: recomenda\u00e7\u00f5es de melhoria\n        \"\"\"\n\n        session = Session()\n        response = await self.runner.run(\n            agent=self.judge_agent,\n            session=session,\n            user_content=prompt\n        )\n\n        try:\n            evaluation = json.loads(response.content)\n            return evaluation\n        except json.JSONDecodeError:\n            return self._extract_json_from_response(response.content)\n\n    async def compare_responses(\n        self,\n        user_query: str,\n        responses: List[Dict[str, str]],\n        context: Optional[Dict[str, Any]] = None\n    ) -&gt; Dict[str, Any]:\n        \"\"\"Compara m\u00faltiplas respostas e ranqueia\"\"\"\n\n        responses_text = \"\\n\\n\".join([\n            f\"Resposta {i+1}:\\n{resp.get('response', '')}\"\n            for i, resp in enumerate(responses)\n        ])\n\n        prompt = f\"\"\"\n        Compare e ranqueie as seguintes respostas:\n\n        Pergunta: {user_query}\n\n        {responses_text}\n\n        Contexto: {json.dumps(context or {}, ensure_ascii=False, indent=2)}\n\n        Forne\u00e7a uma compara\u00e7\u00e3o em JSON com:\n        - rankings: lista ordenada de \u00edndices (melhor primeiro)\n        - scores: pontua\u00e7\u00f5es de 0-1 para cada resposta\n        - comparison: compara\u00e7\u00e3o detalhada entre as respostas\n        - winner: \u00edndice da melhor resposta\n        - reasoning: racioc\u00ednio por tr\u00e1s da decis\u00e3o\n        \"\"\"\n\n        session = Session()\n        response = await self.runner.run(\n            agent=self.judge_agent,\n            session=session,\n            user_content=prompt\n        )\n\n        try:\n            comparison = json.loads(response.content)\n            return comparison\n        except json.JSONDecodeError:\n            return self._extract_json_from_response(response.content)\n\n    def _extract_json_from_response(self, text: str) -&gt; Dict[str, Any]:\n        \"\"\"Extrai JSON de uma resposta que pode conter texto adicional\"\"\"\n        import re\n        json_match = re.search(r'\\{.*\\}', text, re.DOTALL)\n        if json_match:\n            try:\n                return json.loads(json_match.group())\n            except json.JSONDecodeError:\n                pass\n        return {\"error\": \"N\u00e3o foi poss\u00edvel extrair JSON da resposta\", \"raw\": text}\n</code></pre>"},{"location":"LLMs_as_Judge_Study/#323-integracao-com-agentevaluator-do-adk","title":"3.2.3 Integra\u00e7\u00e3o com AgentEvaluator do ADK","text":"<pre><code>from google.adk.evaluation import AgentEvaluator\nfrom typing import List, Dict, Any\n\nclass LLMJudgeEvaluator(AgentEvaluator):\n    \"\"\"Extens\u00e3o do AgentEvaluator do ADK com LLM Judge\"\"\"\n\n    def __init__(\n        self,\n        agent_to_evaluate: Agent,\n        judge: LLMJudge,\n        **kwargs\n    ):\n        super().__init__(agent_to_evaluate, **kwargs)\n        self.judge = judge\n\n    async def evaluate_with_judge(\n        self,\n        test_cases: List[Dict[str, Any]]\n    ) -&gt; Dict[str, Any]:\n        \"\"\"Avalia casos de teste usando LLM Judge\"\"\"\n\n        results = []\n\n        for test_case in test_cases:\n            # Executa o agente sendo avaliado\n            agent_result = await self._run_agent(test_case)\n\n            # Avalia com o judge\n            trajectory_eval = None\n            if test_case.get(\"expected_trajectory\"):\n                trajectory_eval = await self.judge.evaluate_trajectory(\n                    expected_trajectory=test_case[\"expected_trajectory\"],\n                    actual_trajectory=agent_result[\"trajectory\"],\n                    context=test_case.get(\"context\")\n                )\n\n            response_eval = await self.judge.evaluate_response(\n                user_query=test_case[\"user_query\"],\n                agent_response=agent_result[\"response\"],\n                expected_response=test_case.get(\"expected_response\"),\n                context=test_case.get(\"context\")\n            )\n\n            results.append({\n                \"test_case\": test_case,\n                \"agent_result\": agent_result,\n                \"trajectory_evaluation\": trajectory_eval,\n                \"response_evaluation\": response_eval,\n                \"overall_score\": self._calculate_overall_score(\n                    trajectory_eval,\n                    response_eval\n                )\n            })\n\n        return {\n            \"results\": results,\n            \"summary\": self._generate_summary(results)\n        }\n\n    def _calculate_overall_score(\n        self,\n        trajectory_eval: Optional[Dict[str, Any]],\n        response_eval: Dict[str, Any]\n    ) -&gt; float:\n        \"\"\"Calcula pontua\u00e7\u00e3o geral combinando trajet\u00f3ria e resposta\"\"\"\n\n        scores = []\n\n        if trajectory_eval:\n            scores.append(trajectory_eval.get(\"score\", 0))\n\n        if response_eval:\n            scores.append(response_eval.get(\"score\", 0))\n\n        return sum(scores) / len(scores) if scores else 0.0\n\n    def _generate_summary(self, results: List[Dict[str, Any]]) -&gt; Dict[str, Any]:\n        \"\"\"Gera resumo das avalia\u00e7\u00f5es\"\"\"\n\n        scores = [r[\"overall_score\"] for r in results]\n\n        return {\n            \"total_tests\": len(results),\n            \"average_score\": sum(scores) / len(scores) if scores else 0,\n            \"min_score\": min(scores) if scores else 0,\n            \"max_score\": max(scores) if scores else 0,\n            \"pass_rate\": sum(1 for s in scores if s &gt;= 0.7) / len(scores) if scores else 0\n        }\n</code></pre>"},{"location":"LLMs_as_Judge_Study/#4-integracao-com-langfuse","title":"4. Integra\u00e7\u00e3o com Langfuse","text":""},{"location":"LLMs_as_Judge_Study/#41-por-que-integrar-langfuse","title":"4.1 Por que Integrar Langfuse?","text":"<p>Langfuse oferece:</p> <ul> <li>Tracing: Rastreamento completo de execu\u00e7\u00f5es</li> <li>Feedback: Coleta de feedback humano e autom\u00e1tico</li> <li>Analytics: An\u00e1lise de performance e custos</li> <li>Prompt Management: Versionamento e gerenciamento de prompts</li> <li>Scores: Armazenamento de pontua\u00e7\u00f5es de avalia\u00e7\u00e3o</li> </ul>"},{"location":"LLMs_as_Judge_Study/#42-implementacao-de-integracao","title":"4.2 Implementa\u00e7\u00e3o de Integra\u00e7\u00e3o","text":""},{"location":"LLMs_as_Judge_Study/#421-judge-com-tracing-langfuse","title":"4.2.1 Judge com Tracing Langfuse","text":"<pre><code>from langfuse import Langfuse\nfrom langfuse.decorators import langfuse_context\nfrom typing import Dict, Any, Optional\nimport asyncio\n\nclass LangfuseLLMJudge(LLMJudge):\n    \"\"\"LLM Judge integrado com Langfuse para tracing e analytics\"\"\"\n\n    def __init__(\n        self,\n        judge_agent: Agent,\n        runner: Runner,\n        evaluation_criteria: Dict[str, str],\n        langfuse_client: Langfuse\n    ):\n        super().__init__(judge_agent, runner, evaluation_criteria)\n        self.langfuse = langfuse_client\n\n    async def evaluate_trajectory(\n        self,\n        expected_trajectory: List[str],\n        actual_trajectory: List[str],\n        context: Optional[Dict[str, Any]] = None,\n        trace_id: Optional[str] = None\n    ) -&gt; Dict[str, Any]:\n        \"\"\"Avalia trajet\u00f3ria com tracing Langfuse\"\"\"\n\n        # Cria trace no Langfuse\n        trace = self.langfuse.trace(\n            name=\"trajectory_evaluation\",\n            id=trace_id,\n            metadata={\n                \"expected_trajectory\": expected_trajectory,\n                \"actual_trajectory\": actual_trajectory,\n                \"context\": context\n            }\n        )\n\n        try:\n            # Executa avalia\u00e7\u00e3o\n            evaluation = await super().evaluate_trajectory(\n                expected_trajectory,\n                actual_trajectory,\n                context\n            )\n\n            # Registra score no Langfuse\n            trace.score(\n                name=\"trajectory_score\",\n                value=evaluation.get(\"score\", 0),\n                comment=evaluation.get(\"justification\", \"\")\n            )\n\n            # Registra scores individuais\n            for metric, value in evaluation.items():\n                if isinstance(value, (int, float)) and 0 &lt;= value &lt;= 1:\n                    trace.score(\n                        name=f\"trajectory_{metric}\",\n                        value=value\n                    )\n\n            return evaluation\n\n        except Exception as e:\n            trace.update(\n                level=\"ERROR\",\n                status_message=str(e)\n            )\n            raise\n\n    async def evaluate_response(\n        self,\n        user_query: str,\n        agent_response: str,\n        expected_response: Optional[str] = None,\n        context: Optional[Dict[str, Any]] = None,\n        trace_id: Optional[str] = None\n    ) -&gt; Dict[str, Any]:\n        \"\"\"Avalia resposta com tracing Langfuse\"\"\"\n\n        trace = self.langfuse.trace(\n            name=\"response_evaluation\",\n            id=trace_id,\n            input={\n                \"user_query\": user_query,\n                \"agent_response\": agent_response,\n                \"expected_response\": expected_response\n            },\n            metadata=context or {}\n        )\n\n        try:\n            evaluation = await super().evaluate_response(\n                user_query,\n                agent_response,\n                expected_response,\n                context\n            )\n\n            # Registra score geral\n            trace.score(\n                name=\"response_score\",\n                value=evaluation.get(\"score\", 0),\n                comment=evaluation.get(\"justification\", \"\")\n            )\n\n            # Registra scores individuais\n            for metric in [\"correctness\", \"relevance\", \"completeness\", \"clarity\", \"safety\"]:\n                if metric in evaluation:\n                    trace.score(\n                        name=f\"response_{metric}\",\n                        value=evaluation[metric]\n                    )\n\n            # Registra pontos fortes e fracos como observa\u00e7\u00f5es\n            if evaluation.get(\"strengths\"):\n                trace.observation(\n                    name=\"strengths\",\n                    value=evaluation[\"strengths\"]\n                )\n\n            if evaluation.get(\"weaknesses\"):\n                trace.observation(\n                    name=\"weaknesses\",\n                    value=evaluation[\"weaknesses\"]\n                )\n\n            return evaluation\n\n        except Exception as e:\n            trace.update(\n                level=\"ERROR\",\n                status_message=str(e)\n            )\n            raise\n</code></pre>"},{"location":"LLMs_as_Judge_Study/#422-feedback-loop-com-langfuse","title":"4.2.2 Feedback Loop com Langfuse","text":"<pre><code>class LangfuseFeedbackJudge:\n    \"\"\"Integra feedback humano com avalia\u00e7\u00e3o autom\u00e1tica do judge\"\"\"\n\n    def __init__(\n        self,\n        judge: LangfuseLLMJudge,\n        langfuse_client: Langfuse\n    ):\n        self.judge = judge\n        self.langfuse = langfuse_client\n\n    async def evaluate_with_feedback(\n        self,\n        trace_id: str,\n        user_query: str,\n        agent_response: str,\n        human_feedback: Optional[Dict[str, Any]] = None\n    ) -&gt; Dict[str, Any]:\n        \"\"\"Combina avalia\u00e7\u00e3o autom\u00e1tica com feedback humano\"\"\"\n\n        # Avalia\u00e7\u00e3o autom\u00e1tica\n        auto_eval = await self.judge.evaluate_response(\n            user_query=user_query,\n            agent_response=agent_response,\n            trace_id=trace_id\n        )\n\n        # Se houver feedback humano, combina\n        if human_feedback:\n            combined_score = self._combine_scores(\n                auto_eval.get(\"score\", 0),\n                human_feedback.get(\"score\", 0)\n            )\n\n            # Registra feedback humano no Langfuse\n            self.langfuse.score(\n                trace_id=trace_id,\n                name=\"human_feedback\",\n                value=human_feedback.get(\"score\", 0),\n                comment=human_feedback.get(\"comment\", \"\")\n            )\n\n            # Registra score combinado\n            self.langfuse.score(\n                trace_id=trace_id,\n                name=\"combined_score\",\n                value=combined_score,\n                comment=\"Combina\u00e7\u00e3o de avalia\u00e7\u00e3o autom\u00e1tica e feedback humano\"\n            )\n\n            auto_eval[\"human_feedback\"] = human_feedback\n            auto_eval[\"combined_score\"] = combined_score\n\n        return auto_eval\n\n    def _combine_scores(\n        self,\n        auto_score: float,\n        human_score: float,\n        auto_weight: float = 0.7,\n        human_weight: float = 0.3\n    ) -&gt; float:\n        \"\"\"Combina scores autom\u00e1tico e humano com pesos\"\"\"\n        return (auto_score * auto_weight) + (human_score * human_weight)\n</code></pre>"},{"location":"LLMs_as_Judge_Study/#5-exemplos-praticos-completos","title":"5. Exemplos Pr\u00e1ticos Completos","text":""},{"location":"LLMs_as_Judge_Study/#51-exemplo-1-avaliacao-de-agente-rag","title":"5.1 Exemplo 1: Avalia\u00e7\u00e3o de Agente RAG","text":"<pre><code>import asyncio\nfrom google.adk import Agent, Runner, Session\nfrom langfuse import Langfuse\n\n# Configura\u00e7\u00e3o\nlangfuse = Langfuse(\n    secret_key=\"your-secret-key\",\n    public_key=\"your-public-key\",\n    host=\"https://cloud.langfuse.com\"\n)\n\n# Judge Agent\njudge_agent = Agent(\n    name=\"rag_evaluator\",\n    description=\"Especialista em avaliar respostas de agentes RAG\",\n    instruction=\"\"\"\n    Voc\u00ea avalia respostas de agentes RAG considerando:\n    1. Precis\u00e3o das informa\u00e7\u00f5es citadas\n    2. Relev\u00e2ncia das fontes utilizadas\n    3. Completude da resposta\n    4. Clareza na apresenta\u00e7\u00e3o\n\n    Sempre forne\u00e7a JSON estruturado com scores e justificativas.\n    \"\"\",\n    model=\"gemini-2.0-flash\"\n)\n\n# Criar judge\njudge = LangfuseLLMJudge(\n    judge_agent=judge_agent,\n    runner=Runner(),\n    evaluation_criteria={\n        \"accuracy\": \"As informa\u00e7\u00f5es est\u00e3o corretas?\",\n        \"citation_quality\": \"As cita\u00e7\u00f5es s\u00e3o relevantes?\",\n        \"completeness\": \"A resposta est\u00e1 completa?\",\n        \"clarity\": \"A resposta \u00e9 clara?\"\n    },\n    langfuse_client=langfuse\n)\n\n# Casos de teste\ntest_cases = [\n    {\n        \"user_query\": \"Quais s\u00e3o os principais segmentos de neg\u00f3cio da Alphabet?\",\n        \"expected_response\": \"Google Services, Google Cloud, Other Bets\",\n        \"expected_trajectory\": [\"search_documents\", \"retrieve_context\", \"generate_response\"],\n        \"context\": {\"domain\": \"finance\", \"document_type\": \"10-K\"}\n    }\n]\n\n# Executar avalia\u00e7\u00e3o\nasync def evaluate_rag_agent():\n    results = []\n\n    for test_case in test_cases:\n        # Simula execu\u00e7\u00e3o do agente RAG (substitua pelo seu agente real)\n        agent_response = \"A Alphabet possui tr\u00eas segmentos principais...\"\n        agent_trajectory = [\"search_documents\", \"retrieve_context\", \"generate_response\"]\n\n        # Avalia trajet\u00f3ria\n        traj_eval = await judge.evaluate_trajectory(\n            expected_trajectory=test_case[\"expected_trajectory\"],\n            actual_trajectory=agent_trajectory,\n            context=test_case.get(\"context\")\n        )\n\n        # Avalia resposta\n        resp_eval = await judge.evaluate_response(\n            user_query=test_case[\"user_query\"],\n            agent_response=agent_response,\n            expected_response=test_case.get(\"expected_response\"),\n            context=test_case.get(\"context\")\n        )\n\n        results.append({\n            \"test_case\": test_case,\n            \"trajectory_evaluation\": traj_eval,\n            \"response_evaluation\": resp_eval\n        })\n\n    return results\n\n# Executar\n# results = asyncio.run(evaluate_rag_agent())\n</code></pre>"},{"location":"LLMs_as_Judge_Study/#52-exemplo-2-avaliacao-comparativa-de-modelos","title":"5.2 Exemplo 2: Avalia\u00e7\u00e3o Comparativa de Modelos","text":"<pre><code>async def compare_models(\n    user_query: str,\n    responses: List[Dict[str, str]],\n    judge: LLMJudge\n) -&gt; Dict[str, Any]:\n    \"\"\"Compara respostas de diferentes modelos\"\"\"\n\n    comparison = await judge.compare_responses(\n        user_query=user_query,\n        responses=responses\n    )\n\n    print(f\"Melhor resposta: {comparison['winner']}\")\n    print(f\"Scores: {comparison['scores']}\")\n    print(f\"Racioc\u00ednio: {comparison['reasoning']}\")\n\n    return comparison\n\n# Uso\nresponses = [\n    {\"model\": \"gpt-4\", \"response\": \"Resposta do GPT-4...\"},\n    {\"model\": \"gemini-2.0-flash\", \"response\": \"Resposta do Gemini...\"},\n    {\"model\": \"claude-3.5-sonnet\", \"response\": \"Resposta do Claude...\"}\n]\n\ncomparison = asyncio.run(compare_models(\n    user_query=\"Explique o conceito de LLMs as a Judge\",\n    responses=responses,\n    judge=judge\n))\n</code></pre>"},{"location":"LLMs_as_Judge_Study/#53-exemplo-3-pipeline-de-avaliacao-continua","title":"5.3 Exemplo 3: Pipeline de Avalia\u00e7\u00e3o Cont\u00ednua","text":"<pre><code>class ContinuousEvaluationPipeline:\n    \"\"\"Pipeline de avalia\u00e7\u00e3o cont\u00ednua com LLM Judge\"\"\"\n\n    def __init__(\n        self,\n        agent_to_evaluate: Agent,\n        judge: LangfuseLLMJudge,\n        test_suite: List[Dict[str, Any]]\n    ):\n        self.agent = agent_to_evaluate\n        self.judge = judge\n        self.test_suite = test_suite\n        self.runner = Runner()\n\n    async def run_evaluation_cycle(self) -&gt; Dict[str, Any]:\n        \"\"\"Executa um ciclo completo de avalia\u00e7\u00e3o\"\"\"\n\n        results = []\n\n        for test_case in self.test_suite:\n            # Executa agente\n            session = Session()\n            agent_result = await self.runner.run(\n                agent=self.agent,\n                session=session,\n                user_content=test_case[\"user_query\"]\n            )\n\n            # Extrai trajet\u00f3ria (se dispon\u00edvel)\n            trajectory = self._extract_trajectory(agent_result)\n\n            # Avalia com judge\n            trace_id = self.judge.langfuse.get_current_trace_id()\n\n            traj_eval = None\n            if test_case.get(\"expected_trajectory\"):\n                traj_eval = await self.judge.evaluate_trajectory(\n                    expected_trajectory=test_case[\"expected_trajectory\"],\n                    actual_trajectory=trajectory,\n                    trace_id=trace_id\n                )\n\n            resp_eval = await self.judge.evaluate_response(\n                user_query=test_case[\"user_query\"],\n                agent_response=agent_result.content,\n                expected_response=test_case.get(\"expected_response\"),\n                trace_id=trace_id\n            )\n\n            results.append({\n                \"test_case_id\": test_case.get(\"id\"),\n                \"trajectory_evaluation\": traj_eval,\n                \"response_evaluation\": resp_eval,\n                \"trace_id\": trace_id\n            })\n\n        return {\n            \"results\": results,\n            \"summary\": self._generate_summary(results)\n        }\n\n    def _extract_trajectory(self, agent_result) -&gt; List[str]:\n        \"\"\"Extrai trajet\u00f3ria do resultado do agente\"\"\"\n        # Implementar extra\u00e7\u00e3o baseada na estrutura do ADK\n        trajectory = []\n        # Exemplo: percorrer eventos do agente\n        return trajectory\n\n    def _generate_summary(self, results: List[Dict[str, Any]]) -&gt; Dict[str, Any]:\n        \"\"\"Gera resumo das avalia\u00e7\u00f5es\"\"\"\n        scores = [\n            r[\"response_evaluation\"].get(\"score\", 0)\n            for r in results\n            if r.get(\"response_evaluation\")\n        ]\n\n        return {\n            \"total_tests\": len(results),\n            \"average_score\": sum(scores) / len(scores) if scores else 0,\n            \"pass_rate\": sum(1 for s in scores if s &gt;= 0.7) / len(scores) if scores else 0,\n            \"failing_tests\": [\n                r[\"test_case_id\"]\n                for r in results\n                if r.get(\"response_evaluation\", {}).get(\"score\", 0) &lt; 0.7\n            ]\n        }\n</code></pre>"},{"location":"LLMs_as_Judge_Study/#6-metricas-e-benchmarks","title":"6. M\u00e9tricas e Benchmarks","text":""},{"location":"LLMs_as_Judge_Study/#61-metricas-de-qualidade-do-judge","title":"6.1 M\u00e9tricas de Qualidade do Judge","text":""},{"location":"LLMs_as_Judge_Study/#611-consistencia-consistency","title":"6.1.1 Consist\u00eancia (Consistency)","text":"<p>Mede qu\u00e3o consistente o judge \u00e9 em avalia\u00e7\u00f5es similares:</p> <pre><code>def measure_judge_consistency(\n    judge: LLMJudge,\n    test_cases: List[Dict[str, Any]],\n    num_runs: int = 3\n) -&gt; Dict[str, float]:\n    \"\"\"Mede consist\u00eancia do judge executando m\u00faltiplas vezes\"\"\"\n\n    all_scores = []\n\n    for test_case in test_cases:\n        scores = []\n        for _ in range(num_runs):\n            eval_result = await judge.evaluate_response(\n                user_query=test_case[\"user_query\"],\n                agent_response=test_case[\"agent_response\"]\n            )\n            scores.append(eval_result.get(\"score\", 0))\n\n        all_scores.append(scores)\n\n    # Calcula vari\u00e2ncia m\u00e9dia\n    variances = [np.var(scores) for scores in all_scores]\n    avg_variance = np.mean(variances)\n\n    # Calcula coeficiente de varia\u00e7\u00e3o\n    cv_scores = [\n        np.std(scores) / np.mean(scores) if np.mean(scores) &gt; 0 else 0\n        for scores in all_scores\n    ]\n    avg_cv = np.mean(cv_scores)\n\n    return {\n        \"average_variance\": avg_variance,\n        \"average_coefficient_of_variation\": avg_cv,\n        \"consistency_score\": 1 - min(avg_cv, 1.0)  # 0-1, maior \u00e9 melhor\n    }\n</code></pre>"},{"location":"LLMs_as_Judge_Study/#612-correlacao-com-avaliacao-humana","title":"6.1.2 Correla\u00e7\u00e3o com Avalia\u00e7\u00e3o Humana","text":"<pre><code>def measure_human_correlation(\n    judge: LLMJudge,\n    human_evaluations: List[Dict[str, Any]]\n) -&gt; Dict[str, float]:\n    \"\"\"Mede correla\u00e7\u00e3o entre avalia\u00e7\u00e3o do judge e avalia\u00e7\u00e3o humana\"\"\"\n\n    from scipy.stats import pearsonr, spearmanr\n\n    judge_scores = []\n    human_scores = []\n\n    for eval_data in human_evaluations:\n        judge_eval = await judge.evaluate_response(\n            user_query=eval_data[\"user_query\"],\n            agent_response=eval_data[\"agent_response\"]\n        )\n\n        judge_scores.append(judge_eval.get(\"score\", 0))\n        human_scores.append(eval_data[\"human_score\"])\n\n    # Correla\u00e7\u00e3o de Pearson (linear)\n    pearson_corr, pearson_p = pearsonr(judge_scores, human_scores)\n\n    # Correla\u00e7\u00e3o de Spearman (rank)\n    spearman_corr, spearman_p = spearmanr(judge_scores, human_scores)\n\n    return {\n        \"pearson_correlation\": pearson_corr,\n        \"pearson_p_value\": pearson_p,\n        \"spearman_correlation\": spearman_corr,\n        \"spearman_p_value\": spearman_p,\n        \"agreement_rate\": sum(\n            1 for j, h in zip(judge_scores, human_scores)\n            if abs(j - h) &lt; 0.2\n        ) / len(judge_scores)\n    }\n</code></pre>"},{"location":"LLMs_as_Judge_Study/#613-vies-e-justica-bias-and-fairness","title":"6.1.3 Vi\u00e9s e Justi\u00e7a (Bias and Fairness)","text":"<pre><code>def measure_judge_bias(\n    judge: LLMJudge,\n    test_suite: List[Dict[str, Any]]\n) -&gt; Dict[str, Any]:\n    \"\"\"Mede vi\u00e9s do judge em diferentes categorias\"\"\"\n\n    categories = {}\n\n    for test_case in test_suite:\n        category = test_case.get(\"category\", \"unknown\")\n\n        if category not in categories:\n            categories[category] = []\n\n        eval_result = await judge.evaluate_response(\n            user_query=test_case[\"user_query\"],\n            agent_response=test_case[\"agent_response\"]\n        )\n\n        categories[category].append(eval_result.get(\"score\", 0))\n\n    # Calcula m\u00e9dias por categoria\n    category_means = {\n        cat: np.mean(scores)\n        for cat, scores in categories.items()\n    }\n\n    # Identifica disparidades\n    overall_mean = np.mean(list(category_means.values()))\n    disparities = {\n        cat: mean - overall_mean\n        for cat, mean in category_means.items()\n    }\n\n    return {\n        \"category_means\": category_means,\n        \"overall_mean\": overall_mean,\n        \"disparities\": disparities,\n        \"max_disparity\": max(abs(d) for d in disparities.values())\n    }\n</code></pre>"},{"location":"LLMs_as_Judge_Study/#62-benchmarks-recomendados","title":"6.2 Benchmarks Recomendados","text":""},{"location":"LLMs_as_Judge_Study/#621-mt-bench-multi-turn-benchmark","title":"6.2.1 MT-Bench (Multi-Turn Benchmark)","text":"<p>Adaptado para avalia\u00e7\u00e3o de agentes:</p> <pre><code>MT_BENCH_CASES = [\n    {\n        \"category\": \"writing\",\n        \"user_query\": \"Escreva um poema sobre intelig\u00eancia artificial\",\n        \"criteria\": [\"creativity\", \"coherence\", \"literary_quality\"]\n    },\n    {\n        \"category\": \"reasoning\",\n        \"user_query\": \"Resolva este problema de l\u00f3gica: ...\",\n        \"criteria\": [\"correctness\", \"reasoning_quality\", \"explanation\"]\n    },\n    # ... mais casos\n]\n</code></pre>"},{"location":"LLMs_as_Judge_Study/#622-helm-holistic-evaluation-of-language-models","title":"6.2.2 HELM (Holistic Evaluation of Language Models)","text":"<p>Adaptado para agentes:</p> <pre><code>HELM_SCENARIOS = [\n    \"question_answering\",\n    \"summarization\",\n    \"code_generation\",\n    \"reasoning\",\n    \"safety\"\n]\n</code></pre>"},{"location":"LLMs_as_Judge_Study/#63-metricas-de-custo-eficiencia","title":"6.3 M\u00e9tricas de Custo-Efici\u00eancia","text":"<pre><code>def calculate_cost_efficiency(\n    judge: LLMJudge,\n    evaluations: List[Dict[str, Any]],\n    cost_per_token: float\n) -&gt; Dict[str, float]:\n    \"\"\"Calcula custo-efici\u00eancia do judge\"\"\"\n\n    total_tokens = 0\n    total_evaluations = len(evaluations)\n\n    for eval_data in evaluations:\n        # Estima tokens (simplificado)\n        prompt_tokens = estimate_tokens(eval_data[\"prompt\"])\n        response_tokens = estimate_tokens(eval_data[\"response\"])\n        total_tokens += prompt_tokens + response_tokens\n\n    total_cost = total_tokens * cost_per_token\n    cost_per_evaluation = total_cost / total_evaluations\n\n    return {\n        \"total_evaluations\": total_evaluations,\n        \"total_tokens\": total_tokens,\n        \"total_cost\": total_cost,\n        \"cost_per_evaluation\": cost_per_evaluation,\n        \"tokens_per_evaluation\": total_tokens / total_evaluations\n    }\n</code></pre>"},{"location":"LLMs_as_Judge_Study/#7-melhores-praticas","title":"7. Melhores Pr\u00e1ticas","text":""},{"location":"LLMs_as_Judge_Study/#71-design-de-prompts-para-judge","title":"7.1 Design de Prompts para Judge","text":""},{"location":"LLMs_as_Judge_Study/#principios","title":"Princ\u00edpios:","text":"<ol> <li>Seja Espec\u00edfico: Defina claramente os crit\u00e9rios de avalia\u00e7\u00e3o</li> <li>Use Exemplos: Inclua exemplos de boas e m\u00e1s respostas</li> <li>Estruture o Output: Solicite JSON estruturado</li> <li>Defina Escalas: Especifique claramente a escala de pontua\u00e7\u00e3o</li> <li>Pe\u00e7a Justificativas: Solicite explica\u00e7\u00f5es para transpar\u00eancia</li> </ol>"},{"location":"LLMs_as_Judge_Study/#template-de-prompt-recomendado","title":"Template de Prompt Recomendado:","text":"<pre><code>JUDGE_PROMPT_TEMPLATE = \"\"\"\nVoc\u00ea \u00e9 um juiz especializado em avaliar {domain}.\n\nTAREFA:\nAvalie a seguinte resposta de um agente de IA.\n\nPERGUNTA DO USU\u00c1RIO:\n{user_query}\n\nRESPOSTA DO AGENTE:\n{agent_response}\n\n{optional_sections}\n\nCRIT\u00c9RIOS DE AVALIA\u00c7\u00c3O:\n{criteria}\n\nESCALA DE PONTUA\u00c7\u00c3O:\n- 0.0-0.3: Insatisfat\u00f3rio\n- 0.4-0.6: Aceit\u00e1vel\n- 0.7-0.8: Bom\n- 0.9-1.0: Excelente\n\nFORMATO DE RESPOSTA:\nForne\u00e7a sua avalia\u00e7\u00e3o em JSON com a seguinte estrutura:\n{{\n    \"score\": &lt;float 0-1&gt;,\n    \"scores_by_criterion\": {{\n        \"criterion1\": &lt;float 0-1&gt;,\n        \"criterion2\": &lt;float 0-1&gt;\n    }},\n    \"justification\": \"&lt;explica\u00e7\u00e3o detalhada&gt;\",\n    \"strengths\": [\"&lt;ponto forte 1&gt;\", \"&lt;ponto forte 2&gt;\"],\n    \"weaknesses\": [\"&lt;ponto fraco 1&gt;\", \"&lt;ponto fraco 2&gt;\"],\n    \"recommendations\": [\"&lt;recomenda\u00e7\u00e3o 1&gt;\", \"&lt;recomenda\u00e7\u00e3o 2&gt;\"]\n}}\n\nIMPORTANTE:\n- Seja objetivo e justo\n- Considere o contexto fornecido\n- Forne\u00e7a feedback construtivo\n- Justifique suas pontua\u00e7\u00f5es\n\"\"\"\n</code></pre>"},{"location":"LLMs_as_Judge_Study/#72-estrategias-de-reducao-de-custo","title":"7.2 Estrat\u00e9gias de Redu\u00e7\u00e3o de Custo","text":"<ol> <li>Caching: Cache avalia\u00e7\u00f5es de respostas id\u00eanticas</li> <li>Batching: Agrupe m\u00faltiplas avalia\u00e7\u00f5es em uma \u00fanica chamada</li> <li>Modelos Menores: Use modelos menores para avalia\u00e7\u00f5es simples</li> <li>Amostragem: Avalie apenas uma amostra representativa</li> <li>Avalia\u00e7\u00e3o Hier\u00e1rquica: Use judge menor primeiro, judge maior apenas se necess\u00e1rio</li> </ol> <pre><code>class CostOptimizedJudge:\n    \"\"\"Judge otimizado para custo\"\"\"\n\n    def __init__(\n        self,\n        fast_judge: LLMJudge,  # Modelo r\u00e1pido/barato\n        accurate_judge: LLMJudge,  # Modelo preciso/caro\n        threshold: float = 0.7\n    ):\n        self.fast_judge = fast_judge\n        self.accurate_judge = accurate_judge\n        self.threshold = threshold\n        self.cache = {}\n\n    async def evaluate_with_fallback(\n        self,\n        user_query: str,\n        agent_response: str,\n        **kwargs\n    ) -&gt; Dict[str, Any]:\n        \"\"\"Avalia com fallback para judge mais preciso se necess\u00e1rio\"\"\"\n\n        # Verifica cache\n        cache_key = f\"{user_query}:{agent_response}\"\n        if cache_key in self.cache:\n            return self.cache[cache_key]\n\n        # Avalia com judge r\u00e1pido primeiro\n        fast_eval = await self.fast_judge.evaluate_response(\n            user_query=user_query,\n            agent_response=agent_response,\n            **kwargs\n        )\n\n        fast_score = fast_eval.get(\"score\", 0)\n\n        # Se score est\u00e1 pr\u00f3ximo do threshold, usa judge preciso\n        if abs(fast_score - self.threshold) &lt; 0.1:\n            accurate_eval = await self.accurate_judge.evaluate_response(\n                user_query=user_query,\n                agent_response=agent_response,\n                **kwargs\n            )\n            result = accurate_eval\n        else:\n            result = fast_eval\n\n        # Cache resultado\n        self.cache[cache_key] = result\n\n        return result\n</code></pre>"},{"location":"LLMs_as_Judge_Study/#73-tratamento-de-erros-e-edge-cases","title":"7.3 Tratamento de Erros e Edge Cases","text":"<pre><code>class RobustJudge(LLMJudge):\n    \"\"\"Judge com tratamento robusto de erros\"\"\"\n\n    async def evaluate_response(\n        self,\n        user_query: str,\n        agent_response: str,\n        max_retries: int = 3,\n        **kwargs\n    ) -&gt; Dict[str, Any]:\n        \"\"\"Avalia com retry e fallback\"\"\"\n\n        for attempt in range(max_retries):\n            try:\n                result = await super().evaluate_response(\n                    user_query=user_query,\n                    agent_response=agent_response,\n                    **kwargs\n                )\n\n                # Valida resultado\n                if self._validate_result(result):\n                    return result\n                else:\n                    raise ValueError(\"Resultado inv\u00e1lido\")\n\n            except Exception as e:\n                if attempt == max_retries - 1:\n                    # Fallback: retorna avalia\u00e7\u00e3o b\u00e1sica\n                    return self._fallback_evaluation(\n                        user_query=user_query,\n                        agent_response=agent_response,\n                        error=str(e)\n                    )\n\n                # Aguarda antes de retry\n                await asyncio.sleep(2 ** attempt)\n\n        raise RuntimeError(\"Falha ao avaliar ap\u00f3s m\u00faltiplas tentativas\")\n\n    def _validate_result(self, result: Dict[str, Any]) -&gt; bool:\n        \"\"\"Valida estrutura do resultado\"\"\"\n        required_fields = [\"score\", \"justification\"]\n        return all(field in result for field in required_fields) and \\\n               0 &lt;= result.get(\"score\", -1) &lt;= 1\n\n    def _fallback_evaluation(\n        self,\n        user_query: str,\n        agent_response: str,\n        error: str\n    ) -&gt; Dict[str, Any]:\n        \"\"\"Avalia\u00e7\u00e3o b\u00e1sica de fallback\"\"\"\n        return {\n            \"score\": 0.5,  # Score neutro\n            \"justification\": f\"Avalia\u00e7\u00e3o autom\u00e1tica falhou: {error}\",\n            \"error\": True,\n            \"fallback\": True\n        }\n</code></pre>"},{"location":"LLMs_as_Judge_Study/#74-calibracao-do-judge","title":"7.4 Calibra\u00e7\u00e3o do Judge","text":"<pre><code>class CalibratedJudge(LLMJudge):\n    \"\"\"Judge calibrado com dados de refer\u00eancia\"\"\"\n\n    def __init__(self, *args, calibration_data: List[Dict[str, Any]] = None, **kwargs):\n        super().__init__(*args, **kwargs)\n        self.calibration_data = calibration_data or []\n        self.calibration_factor = self._calculate_calibration_factor()\n\n    def _calculate_calibration_factor(self) -&gt; float:\n        \"\"\"Calcula fator de calibra\u00e7\u00e3o baseado em dados de refer\u00eancia\"\"\"\n        if not self.calibration_data:\n            return 1.0\n\n        # Executa avalia\u00e7\u00f5es e compara com refer\u00eancia\n        # Retorna fator de ajuste\n        return 1.0  # Simplificado\n\n    async def evaluate_response(self, *args, **kwargs) -&gt; Dict[str, Any]:\n        \"\"\"Avalia com calibra\u00e7\u00e3o aplicada\"\"\"\n        result = await super().evaluate_response(*args, **kwargs)\n\n        # Aplica calibra\u00e7\u00e3o\n        if \"score\" in result:\n            result[\"score\"] = min(1.0, result[\"score\"] * self.calibration_factor)\n            result[\"original_score\"] = result[\"score\"] / self.calibration_factor\n\n        return result\n</code></pre>"},{"location":"LLMs_as_Judge_Study/#8-casos-de-uso-especificos","title":"8. Casos de Uso Espec\u00edficos","text":""},{"location":"LLMs_as_Judge_Study/#81-avaliacao-de-agentes-conversacionais","title":"8.1 Avalia\u00e7\u00e3o de Agentes Conversacionais","text":"<pre><code>CONVERSATIONAL_JUDGE_CRITERIA = {\n    \"coherence\": \"A resposta \u00e9 coerente com o contexto da conversa?\",\n    \"relevance\": \"A resposta \u00e9 relevante para a pergunta do usu\u00e1rio?\",\n    \"helpfulness\": \"A resposta \u00e9 \u00fatil para o usu\u00e1rio?\",\n    \"naturalness\": \"A resposta soa natural e conversacional?\",\n    \"completeness\": \"A resposta est\u00e1 completa ou precisa de follow-up?\"\n}\n</code></pre>"},{"location":"LLMs_as_Judge_Study/#82-avaliacao-de-agentes-de-codigo","title":"8.2 Avalia\u00e7\u00e3o de Agentes de C\u00f3digo","text":"<pre><code>CODE_JUDGE_CRITERIA = {\n    \"correctness\": \"O c\u00f3digo est\u00e1 correto e funciona?\",\n    \"efficiency\": \"O c\u00f3digo \u00e9 eficiente?\",\n    \"readability\": \"O c\u00f3digo \u00e9 leg\u00edvel e bem estruturado?\",\n    \"best_practices\": \"O c\u00f3digo segue melhores pr\u00e1ticas?\",\n    \"documentation\": \"O c\u00f3digo est\u00e1 bem documentado?\"\n}\n</code></pre>"},{"location":"LLMs_as_Judge_Study/#83-avaliacao-de-agentes-rag","title":"8.3 Avalia\u00e7\u00e3o de Agentes RAG","text":"<pre><code>RAG_JUDGE_CRITERIA = {\n    \"answer_quality\": \"A resposta est\u00e1 correta e completa?\",\n    \"source_relevance\": \"As fontes s\u00e3o relevantes?\",\n    \"citation_accuracy\": \"As cita\u00e7\u00f5es est\u00e3o corretas?\",\n    \"groundedness\": \"A resposta est\u00e1 fundamentada nas fontes?\",\n    \"attribution\": \"A atribui\u00e7\u00e3o \u00e0s fontes est\u00e1 clara?\"\n}\n</code></pre>"},{"location":"LLMs_as_Judge_Study/#9-conclusoes-e-recomendacoes","title":"9. Conclus\u00f5es e Recomenda\u00e7\u00f5es","text":""},{"location":"LLMs_as_Judge_Study/#91-resumo-das-recomendacoes","title":"9.1 Resumo das Recomenda\u00e7\u00f5es","text":""},{"location":"LLMs_as_Judge_Study/#para-projetos-com-google-adk","title":"Para Projetos com Google ADK:","text":"<ol> <li>Judge Principal: Gemini 2.0 Flash</li> <li>Excelente integra\u00e7\u00e3o com ADK</li> <li>Custo-benef\u00edcio ideal</li> <li> <p>Lat\u00eancia baixa</p> </li> <li> <p>Judge para Casos Cr\u00edticos: Gemini 2.0 Pro ou GPT-4o</p> </li> <li>Maior capacidade de racioc\u00ednio</li> <li> <p>Maior consist\u00eancia</p> </li> <li> <p>Integra\u00e7\u00e3o: Use Langfuse para tracing e analytics</p> </li> <li>Rastreamento completo</li> <li>Feedback loops</li> <li>An\u00e1lise de performance</li> </ol>"},{"location":"LLMs_as_Judge_Study/#estrategia-de-implementacao","title":"Estrat\u00e9gia de Implementa\u00e7\u00e3o:","text":"<ol> <li>Fase 1: Implementar judge b\u00e1sico com Gemini 2.0 Flash</li> <li>Fase 2: Integrar com Langfuse para observabilidade</li> <li>Fase 3: Adicionar avalia\u00e7\u00e3o comparativa e benchmarks</li> <li>Fase 4: Otimizar custos e performance</li> <li>Fase 5: Calibrar com dados de produ\u00e7\u00e3o</li> </ol>"},{"location":"LLMs_as_Judge_Study/#92-proximos-passos","title":"9.2 Pr\u00f3ximos Passos","text":"<ol> <li>Implementar POC: Criar prova de conceito com judge b\u00e1sico</li> <li>Coletar Dados: Executar avalia\u00e7\u00f5es em casos reais</li> <li>Calibrar: Ajustar judge com feedback humano</li> <li>Escalar: Expandir para mais casos de uso</li> <li>Monitorar: Acompanhar performance e custos</li> </ol>"},{"location":"LLMs_as_Judge_Study/#93-recursos-adicionais","title":"9.3 Recursos Adicionais","text":"<ul> <li>Google ADK Documentation</li> <li>Langfuse Documentation</li> <li>MT-Bench Paper</li> <li>HELM Benchmark</li> </ul>"},{"location":"LLMs_as_Judge_Study/#10-apendices","title":"10. Ap\u00eandices","text":""},{"location":"LLMs_as_Judge_Study/#101-exemplo-completo-de-implementacao","title":"10.1 Exemplo Completo de Implementa\u00e7\u00e3o","text":"<p>Ver arquivo <code>examples/complete_judge_implementation.py</code> para exemplo completo.</p>"},{"location":"LLMs_as_Judge_Study/#102-templates-de-prompts","title":"10.2 Templates de Prompts","text":"<p>Ver arquivo <code>templates/judge_prompts.py</code> para templates reutiliz\u00e1veis.</p>"},{"location":"LLMs_as_Judge_Study/#103-configuracoes-recomendadas","title":"10.3 Configura\u00e7\u00f5es Recomendadas","text":"<p>Ver arquivo <code>configs/judge_configs.yaml</code> para configura\u00e7\u00f5es recomendadas.</p> <p>Documento criado em: 2024 \u00daltima atualiza\u00e7\u00e3o: 2024 Autor: Equipe de IA Vers\u00e3o: 1.0</p>"},{"location":"QUICK_START_JUDGE/","title":"\ud83d\ude80 Quick Start: LLMs as a Judge","text":"<p>Guia r\u00e1pido para come\u00e7ar a usar LLM Judge em 5 minutos.</p>"},{"location":"QUICK_START_JUDGE/#pre-requisitos","title":"Pr\u00e9-requisitos","text":"<pre><code># Instalar depend\u00eancias\npoetry add langfuse\n\n# Ou com pip\npip install langfuse\n</code></pre>"},{"location":"QUICK_START_JUDGE/#passo-1-configuracao-basica","title":"Passo 1: Configura\u00e7\u00e3o B\u00e1sica","text":"<pre><code>from google.adk import Agent, Runner\nfrom langfuse import Langfuse\nfrom examples.llm_judge_implementation import LangfuseLLMJudge\n\n# 1. Configure o judge agent\njudge_agent = Agent(\n    name=\"evaluation_judge\",\n    description=\"Especialista em avaliar agentes de IA\",\n    instruction=\"\"\"\n    Voc\u00ea \u00e9 um juiz especializado em avaliar agentes de IA.\n    Sempre forne\u00e7a avalia\u00e7\u00f5es em JSON estruturado com scores, justificativas e recomenda\u00e7\u00f5es.\n    \"\"\",\n    model=\"gemini-2.0-flash\"  # Recomendado: melhor custo-benef\u00edcio\n)\n\n# 2. Configure Langfuse (opcional, mas recomendado)\nlangfuse = Langfuse(\n    secret_key=\"sk-lf-...\",  # Sua chave secreta\n    public_key=\"pk-lf-...\",  # Sua chave p\u00fablica\n    host=\"https://cloud.langfuse.com\"\n)\n\n# 3. Crie o judge\nrunner = Runner()\njudge = LangfuseLLMJudge(\n    judge_agent=judge_agent,\n    runner=runner,\n    langfuse_client=langfuse\n)\n</code></pre>"},{"location":"QUICK_START_JUDGE/#passo-2-avaliar-uma-resposta","title":"Passo 2: Avaliar uma Resposta","text":"<pre><code>import asyncio\n\nasync def avaliar_resposta():\n    evaluation = await judge.evaluate_response(\n        user_query=\"O que \u00e9 Python?\",\n        agent_response=\"Python \u00e9 uma linguagem de programa\u00e7\u00e3o de alto n\u00edvel.\",\n        expected_response=\"Python \u00e9 uma linguagem de programa\u00e7\u00e3o interpretada...\"\n    )\n\n    print(f\"\u2705 Score: {evaluation['score']:.2f}\")\n    print(f\"\ud83d\udcdd Justificativa: {evaluation['justification']}\")\n    print(f\"\u2728 Pontos fortes: {evaluation.get('strengths', [])}\")\n    print(f\"\u26a0\ufe0f  Pontos fracos: {evaluation.get('weaknesses', [])}\")\n\n# Executar\nasyncio.run(avaliar_resposta())\n</code></pre>"},{"location":"QUICK_START_JUDGE/#passo-3-avaliar-trajetoria","title":"Passo 3: Avaliar Trajet\u00f3ria","text":"<pre><code>async def avaliar_trajetoria():\n    trajectory_eval = await judge.evaluate_trajectory(\n        expected_trajectory=[\"search\", \"retrieve\", \"generate\"],\n        actual_trajectory=[\"search\", \"retrieve\", \"generate\", \"validate\"]\n    )\n\n    print(f\"\u2705 Score da Trajet\u00f3ria: {trajectory_eval['score']:.2f}\")\n    print(f\"\ud83d\udcca Completude: {trajectory_eval.get('completeness', 0):.2f}\")\n    print(f\"\u26a1 Efici\u00eancia: {trajectory_eval.get('efficiency', 0):.2f}\")\n\nasyncio.run(avaliar_trajetoria())\n</code></pre>"},{"location":"QUICK_START_JUDGE/#passo-4-comparar-multiplas-respostas","title":"Passo 4: Comparar M\u00faltiplas Respostas","text":"<pre><code>async def comparar_respostas():\n    comparison = await judge.compare_responses(\n        user_query=\"Explique machine learning\",\n        responses=[\n            {\"label\": \"GPT-4\", \"response\": \"Machine learning \u00e9...\"},\n            {\"label\": \"Gemini\", \"response\": \"Machine learning \u00e9...\"},\n            {\"label\": \"Claude\", \"response\": \"Machine learning \u00e9...\"}\n        ]\n    )\n\n    print(f\"\ud83c\udfc6 Melhor resposta: {comparison['winner']}\")\n    print(f\"\ud83d\udcca Scores: {comparison['scores']}\")\n    print(f\"\ud83d\udcad Racioc\u00ednio: {comparison['reasoning']}\")\n\nasyncio.run(comparar_respostas())\n</code></pre>"},{"location":"QUICK_START_JUDGE/#passo-5-integrar-com-seu-agente","title":"Passo 5: Integrar com Seu Agente","text":"<pre><code>from google.adk import Agent, Runner, Session\n\n# Seu agente\nmeu_agente = Agent(\n    name=\"meu_agente\",\n    description=\"...\",\n    instruction=\"...\",\n    model=\"gemini-2.0-flash\"\n)\n\nasync def avaliar_meu_agente():\n    runner = Runner()\n    session = Session()\n\n    # Executa seu agente\n    user_query = \"Qual \u00e9 a capital do Brasil?\"\n    response = await runner.run(\n        agent=meu_agente,\n        session=session,\n        user_content=user_query\n    )\n\n    # Avalia com judge\n    evaluation = await judge.evaluate_response(\n        user_query=user_query,\n        agent_response=response.content\n    )\n\n    print(f\"Resposta do agente: {response.content}\")\n    print(f\"Score: {evaluation['score']:.2f}\")\n\n    return evaluation\n\nasyncio.run(avaliar_meu_agente())\n</code></pre>"},{"location":"QUICK_START_JUDGE/#exemplo-completo-pipeline-de-avaliacao","title":"Exemplo Completo: Pipeline de Avalia\u00e7\u00e3o","text":"<pre><code>async def pipeline_completo():\n    \"\"\"Pipeline completo de avalia\u00e7\u00e3o\"\"\"\n\n    # Casos de teste\n    test_cases = [\n        {\n            \"user_query\": \"O que \u00e9 Python?\",\n            \"expected_response\": \"Python \u00e9 uma linguagem de programa\u00e7\u00e3o...\"\n        },\n        {\n            \"user_query\": \"Explique machine learning\",\n            \"expected_response\": \"Machine learning \u00e9 um subcampo da IA...\"\n        }\n    ]\n\n    results = []\n\n    for test_case in test_cases:\n        # Executa agente (substitua pelo seu agente real)\n        agent_response = \"...\"  # Resposta do seu agente\n\n        # Avalia\n        evaluation = await judge.evaluate_response(\n            user_query=test_case[\"user_query\"],\n            agent_response=agent_response,\n            expected_response=test_case.get(\"expected_response\")\n        )\n\n        results.append({\n            \"test_case\": test_case[\"user_query\"],\n            \"score\": evaluation[\"score\"],\n            \"evaluation\": evaluation\n        })\n\n    # Resumo\n    avg_score = sum(r[\"score\"] for r in results) / len(results)\n    print(f\"\ud83d\udcca Score M\u00e9dio: {avg_score:.2f}\")\n    print(f\"\u2705 Testes Passados: {sum(1 for r in results if r['score'] &gt;= 0.7)}/{len(results)}\")\n\n    return results\n\nasyncio.run(pipeline_completo())\n</code></pre>"},{"location":"QUICK_START_JUDGE/#configuracao-avancada","title":"Configura\u00e7\u00e3o Avan\u00e7ada","text":""},{"location":"QUICK_START_JUDGE/#usar-criterios-customizados","title":"Usar Crit\u00e9rios Customizados","text":"<pre><code>custom_criteria = {\n    \"correctness\": \"A resposta est\u00e1 correta?\",\n    \"relevance\": \"A resposta \u00e9 relevante?\",\n    \"completeness\": \"A resposta est\u00e1 completa?\",\n    \"clarity\": \"A resposta \u00e9 clara?\",\n    \"safety\": \"A resposta \u00e9 segura?\"\n}\n\njudge = LangfuseLLMJudge(\n    judge_agent=judge_agent,\n    runner=runner,\n    langfuse_client=langfuse,\n    evaluation_criteria=custom_criteria\n)\n</code></pre>"},{"location":"QUICK_START_JUDGE/#usar-modelo-diferente","title":"Usar Modelo Diferente","text":"<pre><code># Para casos cr\u00edticos, use modelo mais poderoso\njudge_agent_critical = Agent(\n    name=\"evaluation_judge_critical\",\n    description=\"...\",\n    instruction=\"...\",\n    model=\"gemini-2.0-pro\"  # ou \"gpt-4o\"\n)\n</code></pre>"},{"location":"QUICK_START_JUDGE/#sem-langfuse-modo-simples","title":"Sem Langfuse (Modo Simples)","text":"<pre><code>from examples.llm_judge_implementation import LLMJudge\n\n# Judge sem Langfuse\njudge_simple = LLMJudge(\n    judge_agent=judge_agent,\n    runner=runner\n)\n</code></pre>"},{"location":"QUICK_START_JUDGE/#troubleshooting","title":"Troubleshooting","text":""},{"location":"QUICK_START_JUDGE/#erro-nao-foi-possivel-extrair-json","title":"Erro: \"N\u00e3o foi poss\u00edvel extrair JSON\"","text":"<ul> <li>O judge pode n\u00e3o estar retornando JSON v\u00e1lido</li> <li>Solu\u00e7\u00e3o: Verifique o prompt do judge agent</li> </ul>"},{"location":"QUICK_START_JUDGE/#erro-langfuse-connection-failed","title":"Erro: \"Langfuse connection failed\"","text":"<ul> <li>Langfuse n\u00e3o est\u00e1 configurado corretamente</li> <li>Solu\u00e7\u00e3o: Use <code>LLMJudge</code> sem Langfuse ou verifique credenciais</li> </ul>"},{"location":"QUICK_START_JUDGE/#avaliacoes-inconsistentes","title":"Avalia\u00e7\u00f5es Inconsistentes","text":"<ul> <li>Modelos podem variar entre execu\u00e7\u00f5es</li> <li>Solu\u00e7\u00e3o: Use <code>temperature=0.0</code> no judge agent</li> </ul>"},{"location":"QUICK_START_JUDGE/#proximos-passos","title":"Pr\u00f3ximos Passos","text":"<ol> <li>\u2705 Leia o estudo completo: <code>docs/LLMs_as_Judge_Study.md</code></li> <li>\u2705 Explore exemplos: <code>examples/llm_judge_implementation.py</code></li> <li>\u2705 Configure Langfuse para observabilidade</li> <li>\u2705 Adapte para seus casos de uso espec\u00edficos</li> </ol>"},{"location":"QUICK_START_JUDGE/#recursos","title":"Recursos","text":"<ul> <li>\ud83d\udcda Estudo Completo: <code>docs/LLMs_as_Judge_Study.md</code></li> <li>\ud83d\udcdd Resumo Executivo: <code>docs/RESUMO_EXECUTIVO_LLMs_Judge.md</code></li> <li>\ud83d\udcbb Exemplos: <code>examples/</code></li> <li>\u2699\ufe0f Configura\u00e7\u00f5es: <code>examples/judge_configs.yaml</code></li> </ul> <p>Pronto para come\u00e7ar! \ud83d\ude80</p>"},{"location":"RESUMO_EXECUTIVO_LLMs_Judge/","title":"\ud83d\udcca Resumo Executivo: LLMs as a Judge","text":""},{"location":"RESUMO_EXECUTIVO_LLMs_Judge/#visao-geral","title":"Vis\u00e3o Geral","text":"<p>Este documento apresenta um resumo executivo do estudo sobre LLMs as a Judge - t\u00e9cnica de usar modelos de linguagem grandes para avaliar automaticamente a qualidade de agentes de IA.</p>"},{"location":"RESUMO_EXECUTIVO_LLMs_Judge/#principais-conclusoes","title":"Principais Conclus\u00f5es","text":""},{"location":"RESUMO_EXECUTIVO_LLMs_Judge/#1-modelos-recomendados","title":"1. Modelos Recomendados","text":""},{"location":"RESUMO_EXECUTIVO_LLMs_Judge/#para-uso-geral-recomendado","title":"Para Uso Geral (Recomendado)","text":"<ul> <li>Gemini 2.0 Flash: Melhor custo-benef\u00edcio, lat\u00eancia baixa, integra\u00e7\u00e3o nativa com ADK</li> <li>Claude 3 Haiku: Alternativa de baixo custo e alta velocidade</li> </ul>"},{"location":"RESUMO_EXECUTIVO_LLMs_Judge/#para-casos-criticos","title":"Para Casos Cr\u00edticos","text":"<ul> <li>GPT-4o: M\u00e1xima precis\u00e3o e consist\u00eancia</li> <li>Gemini 2.0 Pro: Excelente para casos complexos com contexto longo</li> <li>Claude 3.5 Sonnet: Alta qualidade de an\u00e1lise</li> </ul>"},{"location":"RESUMO_EXECUTIVO_LLMs_Judge/#2-tipos-de-avaliacao","title":"2. Tipos de Avalia\u00e7\u00e3o","text":"<ol> <li>Trajet\u00f3ria: Avalia sequ\u00eancia de a\u00e7\u00f5es do agente</li> <li>Qualidade de Resposta: Avalia corre\u00e7\u00e3o, relev\u00e2ncia, completude</li> <li>Comparativa: Compara e ranqueia m\u00faltiplas respostas</li> <li>Comportamental: Avalia alinhamento e \u00e9tica</li> </ol>"},{"location":"RESUMO_EXECUTIVO_LLMs_Judge/#3-integracao-recomendada","title":"3. Integra\u00e7\u00e3o Recomendada","text":"<pre><code>Agente ADK \u2192 AgentEvaluator \u2192 LLM Judge \u2192 Langfuse\n</code></pre> <ul> <li>ADK: Framework de agentes</li> <li>LLM Judge: Avalia\u00e7\u00e3o autom\u00e1tica</li> <li>Langfuse: Tracing, analytics e feedback</li> </ul>"},{"location":"RESUMO_EXECUTIVO_LLMs_Judge/#recomendacoes-praticas","title":"Recomenda\u00e7\u00f5es Pr\u00e1ticas","text":""},{"location":"RESUMO_EXECUTIVO_LLMs_Judge/#estrategia-de-implementacao","title":"Estrat\u00e9gia de Implementa\u00e7\u00e3o","text":"<ol> <li>Fase 1: Implementar judge b\u00e1sico com Gemini 2.0 Flash</li> <li>Fase 2: Integrar com Langfuse para observabilidade</li> <li>Fase 3: Adicionar avalia\u00e7\u00e3o comparativa</li> <li>Fase 4: Otimizar custos e performance</li> <li>Fase 5: Calibrar com dados de produ\u00e7\u00e3o</li> </ol>"},{"location":"RESUMO_EXECUTIVO_LLMs_Judge/#otimizacao-de-custo","title":"Otimiza\u00e7\u00e3o de Custo","text":"<ul> <li>Caching: Cache avalia\u00e7\u00f5es id\u00eanticas</li> <li>Avalia\u00e7\u00e3o Hier\u00e1rquica: Use modelo r\u00e1pido primeiro, modelo preciso apenas se necess\u00e1rio</li> <li>Amostragem: Avalie amostra representativa em larga escala</li> <li>Batching: Agrupe m\u00faltiplas avalia\u00e7\u00f5es quando poss\u00edvel</li> </ul>"},{"location":"RESUMO_EXECUTIVO_LLMs_Judge/#melhores-praticas","title":"Melhores Pr\u00e1ticas","text":"<ol> <li>Prompts Espec\u00edficos: Defina claramente crit\u00e9rios de avalia\u00e7\u00e3o</li> <li>Output Estruturado: Solicite JSON estruturado para facilitar parsing</li> <li>Justificativas: Pe\u00e7a explica\u00e7\u00f5es para transpar\u00eancia</li> <li>Valida\u00e7\u00e3o: Valide resultados antes de usar</li> <li>Retry Logic: Implemente retry com fallback</li> </ol>"},{"location":"RESUMO_EXECUTIVO_LLMs_Judge/#metricas-importantes","title":"M\u00e9tricas Importantes","text":""},{"location":"RESUMO_EXECUTIVO_LLMs_Judge/#consistencia","title":"Consist\u00eancia","text":"<ul> <li>Vari\u00e2ncia entre avalia\u00e7\u00f5es similares</li> <li>Coeficiente de varia\u00e7\u00e3o</li> <li>Meta: &lt; 0.1 de vari\u00e2ncia</li> </ul>"},{"location":"RESUMO_EXECUTIVO_LLMs_Judge/#correlacao-com-humanos","title":"Correla\u00e7\u00e3o com Humanos","text":"<ul> <li>Correla\u00e7\u00e3o de Pearson (linear)</li> <li>Correla\u00e7\u00e3o de Spearman (rank)</li> <li>Meta: &gt; 0.7 de correla\u00e7\u00e3o</li> </ul>"},{"location":"RESUMO_EXECUTIVO_LLMs_Judge/#custo-eficiencia","title":"Custo-Efici\u00eancia","text":"<ul> <li>Custo por avalia\u00e7\u00e3o</li> <li>Tokens por avalia\u00e7\u00e3o</li> <li>Meta: Otimizar para uso em produ\u00e7\u00e3o</li> </ul>"},{"location":"RESUMO_EXECUTIVO_LLMs_Judge/#casos-de-uso-especificos","title":"Casos de Uso Espec\u00edficos","text":""},{"location":"RESUMO_EXECUTIVO_LLMs_Judge/#agentes-conversacionais","title":"Agentes Conversacionais","text":"<ul> <li>Foco: Coer\u00eancia, relev\u00e2ncia, naturalidade</li> <li>Modelo: Gemini 2.0 Flash</li> </ul>"},{"location":"RESUMO_EXECUTIVO_LLMs_Judge/#agentes-de-codigo","title":"Agentes de C\u00f3digo","text":"<ul> <li>Foco: Corre\u00e7\u00e3o, efici\u00eancia, melhores pr\u00e1ticas</li> <li>Modelo: Gemini 2.0 Pro ou GPT-4o</li> </ul>"},{"location":"RESUMO_EXECUTIVO_LLMs_Judge/#agentes-rag","title":"Agentes RAG","text":"<ul> <li>Foco: Qualidade da resposta, relev\u00e2ncia de fontes, cita\u00e7\u00f5es</li> <li>Modelo: Gemini 2.0 Flash</li> </ul>"},{"location":"RESUMO_EXECUTIVO_LLMs_Judge/#proximos-passos","title":"Pr\u00f3ximos Passos","text":"<ol> <li>\u2705 Leia o estudo completo: <code>docs/LLMs_as_Judge_Study.md</code></li> <li>\u2705 Revise exemplos pr\u00e1ticos: <code>examples/llm_judge_implementation.py</code></li> <li>\u2705 Configure ambiente com Langfuse</li> <li>\u2705 Implemente POC b\u00e1sico</li> <li>\u2705 Colete dados e calibre judge</li> <li>\u2705 Escale para produ\u00e7\u00e3o</li> </ol>"},{"location":"RESUMO_EXECUTIVO_LLMs_Judge/#recursos","title":"Recursos","text":"<ul> <li>Estudo Completo: <code>docs/LLMs_as_Judge_Study.md</code></li> <li>Exemplos de C\u00f3digo: <code>examples/</code></li> <li>Templates de Prompts: <code>examples/judge_prompts_templates.py</code></li> <li>Configura\u00e7\u00f5es: <code>examples/judge_configs.yaml</code></li> </ul>"},{"location":"RESUMO_EXECUTIVO_LLMs_Judge/#contato-e-suporte","title":"Contato e Suporte","text":"<p>Para d\u00favidas ou sugest\u00f5es sobre este estudo, consulte a documenta\u00e7\u00e3o completa ou entre em contato com a equipe de IA.</p> <p>Vers\u00e3o: 1.0 Data: 2024 Status: \u2705 Completo e Pronto para Uso</p>"}]}